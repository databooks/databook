{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple #豆瓣源，可以换成其他的源, https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (1.0.1.post2)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (0.2.2.post3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.6/site-packages (from torchvision) (6.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from torchvision) (1.16.3)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6341, 0.0707, 0.1996],\n",
      "        [0.5852, 0.2857, 0.2922],\n",
      "        [0.0604, 0.7841, 0.3326],\n",
      "        [0.6744, 0.2574, 0.1876],\n",
      "        [0.6627, 0.1217, 0.2046]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torchvision:\n",
      "\n",
      "NAME\n",
      "    torchvision\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _C\n",
      "    datasets (package)\n",
      "    models (package)\n",
      "    ops (package)\n",
      "    transforms (package)\n",
      "    utils\n",
      "    version\n",
      "\n",
      "FUNCTIONS\n",
      "    get_image_backend()\n",
      "        Gets the name of the package used to load images\n",
      "    \n",
      "    set_image_backend(backend)\n",
      "        Specifies the package used to load images.\n",
      "        \n",
      "        Args:\n",
      "            backend (string): Name of the image backend. one of {'PIL', 'accimage'}.\n",
      "                The :mod:`accimage` package uses the Intel IPP library. It is\n",
      "                generally faster than PIL, but does not support as many operations.\n",
      "\n",
      "VERSION\n",
      "    0.3.0\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.6/site-packages/torchvision/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "help(torchvision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch:\n",
      "\n",
      "NAME\n",
      "    torch\n",
      "\n",
      "DESCRIPTION\n",
      "    The torch package contains data structures for multi-dimensional\n",
      "    tensors and mathematical operations over these are defined.\n",
      "    Additionally, it provides many utilities for efficient serializing of\n",
      "    Tensors and arbitrary types, and other useful utilities.\n",
      "    \n",
      "    It has a CUDA counterpart, that enables you to run your tensor computations\n",
      "    on an NVIDIA GPU with compute capability >= 3.0.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _C\n",
      "    __config__\n",
      "    _dl\n",
      "    _jit_internal\n",
      "    _ops\n",
      "    _six\n",
      "    _storage_docs\n",
      "    _tensor_docs\n",
      "    _tensor_str\n",
      "    _thnn (package)\n",
      "    _torch_docs\n",
      "    _utils\n",
      "    _utils_internal\n",
      "    autograd (package)\n",
      "    backends (package)\n",
      "    contrib (package)\n",
      "    cuda (package)\n",
      "    distributed (package)\n",
      "    distributions (package)\n",
      "    for_onnx (package)\n",
      "    functional\n",
      "    hub\n",
      "    jit (package)\n",
      "    multiprocessing (package)\n",
      "    nn (package)\n",
      "    onnx (package)\n",
      "    optim (package)\n",
      "    quasirandom\n",
      "    random\n",
      "    serialization\n",
      "    sparse (package)\n",
      "    storage\n",
      "    tensor\n",
      "    testing (package)\n",
      "    utils (package)\n",
      "    version\n",
      "\n",
      "SUBMODULES\n",
      "    cpp\n",
      "    ops\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        FatalError\n",
      "        torch._C.JITException\n",
      "    builtins.object\n",
      "        ByteTensor\n",
      "        CharTensor\n",
      "        DoubleTensor\n",
      "        FloatTensor\n",
      "        IntTensor\n",
      "        LongTensor\n",
      "        ShortTensor\n",
      "        device\n",
      "        dtype\n",
      "        finfo\n",
      "        iinfo\n",
      "        layout\n",
      "        torch._C.Generator\n",
      "        torch.autograd.grad_mode.enable_grad\n",
      "        torch.autograd.grad_mode.no_grad\n",
      "        torch.autograd.grad_mode.set_grad_enabled\n",
      "    builtins.tuple(builtins.object)\n",
      "        Size\n",
      "    pybind11_builtins.pybind11_object(builtins.object)\n",
      "        torch._C.AggregationType\n",
      "        torch._C.Argument\n",
      "        torch._C.ArgumentSpec\n",
      "        torch._C.Block\n",
      "        torch._C.Code\n",
      "        torch._C.CompilationUnit\n",
      "        torch._C.CompleteArgumentSpec\n",
      "        torch._C.ExecutionPlanState\n",
      "        torch._C.ExtraFilesMap\n",
      "        torch._C.FileCheck\n",
      "        torch._C.Function\n",
      "        torch._C.FunctionSchema\n",
      "        torch._C.Future\n",
      "        torch._C.Gradient\n",
      "        torch._C.Graph\n",
      "        torch._C.GraphExecutorState\n",
      "        torch._C.IODescriptor\n",
      "        torch._C.Node\n",
      "        torch._C.PyTorchFileReader\n",
      "        torch._C.PyTorchFileWriter\n",
      "        torch._C.ScriptMethod\n",
      "        torch._C.ScriptModule\n",
      "        torch._C.TracingState\n",
      "        torch._C.Type\n",
      "            torch._C.BoolType\n",
      "            torch._C.DictType\n",
      "            torch._C.FloatType\n",
      "            torch._C.IntType\n",
      "            torch._C.ListType\n",
      "            torch._C.NumberType\n",
      "            torch._C.OptionalType\n",
      "            torch._C.StringType\n",
      "            torch._C.TensorType\n",
      "            torch._C.TupleType\n",
      "        torch._C.Use\n",
      "        torch._C.Value\n",
      "    torch._C.ByteStorageBase(builtins.object)\n",
      "        ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.CharStorageBase(builtins.object)\n",
      "        CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.DoubleStorageBase(builtins.object)\n",
      "        DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.FloatStorageBase(builtins.object)\n",
      "        FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.IntStorageBase(builtins.object)\n",
      "        IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.LoggerBase(pybind11_builtins.pybind11_object)\n",
      "        torch._C.LockingLogger\n",
      "        torch._C.NoopLogger\n",
      "    torch._C.LongStorageBase(builtins.object)\n",
      "        LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "    torch._C.ShortStorageBase(builtins.object)\n",
      "        ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "    torch._C._TensorBase(builtins.object)\n",
      "        Tensor\n",
      "    torch.storage._StorageBase(builtins.object)\n",
      "        ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "        CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "        DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "        FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "        IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "        LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "        ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "    \n",
      "    class AggregationType(pybind11_builtins.pybind11_object)\n",
      "     |  Members:\n",
      "     |  \n",
      "     |  SUM\n",
      "     |  \n",
      "     |  AVG\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AggregationType\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__ = (...)\n",
      "     |      (self: object, arg0: object) -> bool\n",
      "     |  \n",
      "     |  __getstate__ = (...)\n",
      "     |      (self: object) -> int_\n",
      "     |  \n",
      "     |  __hash__ = (...)\n",
      "     |      (self: object) -> int_\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.AggregationType, arg0: int) -> None\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |      __int__(self: torch._C.AggregationType) -> int\n",
      "     |  \n",
      "     |  __ne__ = (...)\n",
      "     |      (self: object, arg0: object) -> bool\n",
      "     |  \n",
      "     |  __repr__ = (...)\n",
      "     |      (self: handle) -> str\n",
      "     |  \n",
      "     |  __setstate__ = (...)\n",
      "     |      (self: torch._C.AggregationType, arg0: int) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |  \n",
      "     |  name\n",
      "     |      (self: handle) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AVG = AggregationType.AVG\n",
      "     |  \n",
      "     |  SUM = AggregationType.SUM\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Argument(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Argument\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  N\n",
      "     |  \n",
      "     |  default_value\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ArgumentSpec(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ArgumentSpec\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Block(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Block\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Block, kind: str, recurse: bool = True) -> List[torch::jit::Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Block, kind: str, recurse: bool = True) -> torch::jit::Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Block) -> iterator\n",
      "     |  \n",
      "     |  nodes(...)\n",
      "     |      nodes(self: torch._C.Block) -> iterator\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Block) -> iterator\n",
      "     |  \n",
      "     |  paramNode(...)\n",
      "     |      paramNode(self: torch._C.Block) -> torch::jit::Node\n",
      "     |  \n",
      "     |  returnNode(...)\n",
      "     |      returnNode(self: torch._C.Block) -> torch::jit::Node\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class BoolType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      BoolType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.BoolType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ByteStorage(torch._C.ByteStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ByteStorage\n",
      "     |      torch._C.ByteStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.ByteStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class ByteTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(0, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [1, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([0, 0, 0, 1], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(1, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.any(dim=1)\n",
      "     |          tensor([1, 0, 1, 0], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrifact_with_info(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrisolve(self, LU_data, LU_pivots)\n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of dense dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(self, A)\n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(self, upper=True)\n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  potri(self, upper=True)\n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  potrs(self, u, upper=True)\n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(self, upper=True)\n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  quantize_linear(...)\n",
      "     |      quantize_linear(scale, zero_point) -> Tensor\n",
      "     |      \n",
      "     |      Quantize a float Tensor using affine quantization scheme with given scale and\n",
      "     |      zero_point.\n",
      "     |      returns the quantized Tensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of sparse dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(self, A, upper=True, transpose=False, unitriangular=False)\n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.uint8\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class CharStorage(torch._C.CharStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      CharStorage\n",
      "     |      torch._C.CharStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.CharStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class CharTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(0, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [1, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([0, 0, 0, 1], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(1, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.any(dim=1)\n",
      "     |          tensor([1, 0, 1, 0], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrifact_with_info(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrisolve(self, LU_data, LU_pivots)\n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of dense dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(self, A)\n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(self, upper=True)\n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  potri(self, upper=True)\n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  potrs(self, u, upper=True)\n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(self, upper=True)\n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  quantize_linear(...)\n",
      "     |      quantize_linear(scale, zero_point) -> Tensor\n",
      "     |      \n",
      "     |      Quantize a float Tensor using affine quantization scheme with given scale and\n",
      "     |      zero_point.\n",
      "     |      returns the quantized Tensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of sparse dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(self, A, upper=True, transpose=False, unitriangular=False)\n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int8\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class Code(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Code\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  grad_executor_states(...)\n",
      "     |      grad_executor_states(self: torch._C.Code) -> List[torch::jit::GraphExecutorState]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CompilationUnit(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      CompilationUnit\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.CompilationUnit) -> None\n",
      "     |  \n",
      "     |  define(...)\n",
      "     |      define(self: torch._C.CompilationUnit, arg0: str, arg1: Callable[[str], function]) -> None\n",
      "     |  \n",
      "     |  find_function(...)\n",
      "     |      find_function(self: torch._C.CompilationUnit, arg0: str) -> torch::jit::script::Function\n",
      "     |  \n",
      "     |  set_optimized(...)\n",
      "     |      set_optimized(self: torch._C.CompilationUnit, arg0: bool) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class CompleteArgumentSpec(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      CompleteArgumentSpec\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.CompleteArgumentSpec) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DictType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      DictType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.DictType, arg0: torch._C.Type, arg1: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class DoubleStorage(torch._C.DoubleStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      DoubleStorage\n",
      "     |      torch._C.DoubleStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.DoubleStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class DoubleTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(0, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [1, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([0, 0, 0, 1], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(1, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.any(dim=1)\n",
      "     |          tensor([1, 0, 1, 0], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrifact_with_info(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrisolve(self, LU_data, LU_pivots)\n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of dense dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(self, A)\n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(self, upper=True)\n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  potri(self, upper=True)\n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  potrs(self, u, upper=True)\n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(self, upper=True)\n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  quantize_linear(...)\n",
      "     |      quantize_linear(scale, zero_point) -> Tensor\n",
      "     |      \n",
      "     |      Quantize a float Tensor using affine quantization scheme with given scale and\n",
      "     |      zero_point.\n",
      "     |      returns the quantized Tensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of sparse dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(self, A, upper=True, transpose=False, unitriangular=False)\n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float64\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class ExecutionPlanState(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ExecutionPlanState\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ExtraFilesMap(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ExtraFilesMap\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |      __bool__(self: torch._C.ExtraFilesMap) -> bool\n",
      "     |      \n",
      "     |      Check whether the map is nonempty\n",
      "     |  \n",
      "     |  __delitem__(...)\n",
      "     |      __delitem__(self: torch._C.ExtraFilesMap, arg0: str) -> None\n",
      "     |  \n",
      "     |  __getitem__(...)\n",
      "     |      __getitem__(self: torch._C.ExtraFilesMap, arg0: str) -> str\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ExtraFilesMap) -> None\n",
      "     |  \n",
      "     |  __iter__(...)\n",
      "     |      __iter__(self: torch._C.ExtraFilesMap) -> iterator\n",
      "     |  \n",
      "     |  __len__(...)\n",
      "     |      __len__(self: torch._C.ExtraFilesMap) -> int\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.ExtraFilesMap) -> str\n",
      "     |      \n",
      "     |      Return the canonical string representation of this map.\n",
      "     |  \n",
      "     |  __setitem__(...)\n",
      "     |      __setitem__(self: torch._C.ExtraFilesMap, arg0: str, arg1: str) -> None\n",
      "     |  \n",
      "     |  items(...)\n",
      "     |      items(self: torch._C.ExtraFilesMap) -> iterator\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pybind11_module_local_v3__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FatalError(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FatalError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class FileCheck(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      FileCheck\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.FileCheck) -> None\n",
      "     |  \n",
      "     |  check(...)\n",
      "     |      check(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_count(...)\n",
      "     |      check_count(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. check_count(self: torch._C.FileCheck, arg0: str, arg1: int, arg2: bool) -> torch._C.FileCheck\n",
      "     |      \n",
      "     |      2. check_count(self: torch._C.FileCheck, arg0: str, arg1: int, arg2: bool) -> torch._C.FileCheck\n",
      "     |      \n",
      "     |      3. check_count(self: torch._C.FileCheck, str: str, count: int, exactly: bool = False) -> torch._C.FileCheck\n",
      "     |      \n",
      "     |      Check Count\n",
      "     |  \n",
      "     |  check_dag(...)\n",
      "     |      check_dag(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_next(...)\n",
      "     |      check_next(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_not(...)\n",
      "     |      check_not(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  check_same(...)\n",
      "     |      check_same(self: torch._C.FileCheck, arg0: str) -> torch._C.FileCheck\n",
      "     |  \n",
      "     |  run(...)\n",
      "     |      run(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. run(self: torch._C.FileCheck, arg0: str) -> None\n",
      "     |      \n",
      "     |      2. run(self: torch._C.FileCheck, arg0: torch._C.Graph) -> None\n",
      "     |      \n",
      "     |      3. run(self: torch._C.FileCheck, checks_file: str, test_file: str) -> None\n",
      "     |      \n",
      "     |      Run\n",
      "     |      \n",
      "     |      4. run(self: torch._C.FileCheck, checks_file: str, graph: torch._C.Graph) -> None\n",
      "     |      \n",
      "     |      Run\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FloatStorage(torch._C.FloatStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      FloatStorage\n",
      "     |      torch._C.FloatStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.FloatStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class FloatTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(0, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [1, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([0, 0, 0, 1], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(1, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.any(dim=1)\n",
      "     |          tensor([1, 0, 1, 0], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrifact_with_info(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrisolve(self, LU_data, LU_pivots)\n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of dense dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(self, A)\n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(self, upper=True)\n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  potri(self, upper=True)\n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  potrs(self, u, upper=True)\n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(self, upper=True)\n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  quantize_linear(...)\n",
      "     |      quantize_linear(scale, zero_point) -> Tensor\n",
      "     |      \n",
      "     |      Quantize a float Tensor using affine quantization scheme with given scale and\n",
      "     |      zero_point.\n",
      "     |      returns the quantized Tensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of sparse dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(self, A, upper=True, transpose=False, unitriangular=False)\n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.float32\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class FloatType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      FloatType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.FloatType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Function(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Function\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(*args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_debug_state(...)\n",
      "     |      get_debug_state(self: torch._C.Function) -> torch._C.GraphExecutorState\n",
      "     |  \n",
      "     |  graph_for = _graph_for(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  schema\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class FunctionSchema(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      FunctionSchema\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.FunctionSchema) -> str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  arguments\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  overload_name\n",
      "     |  \n",
      "     |  returns\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Future(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Future\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Generator(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  get_state(...)\n",
      "     |  \n",
      "     |  initial_seed(...)\n",
      "     |  \n",
      "     |  manual_seed(...)\n",
      "     |  \n",
      "     |  seed(...)\n",
      "     |  \n",
      "     |  set_state(...)\n",
      "    \n",
      "    class Gradient(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Gradient\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  df\n",
      "     |  \n",
      "     |  df_input_captured_inputs\n",
      "     |  \n",
      "     |  df_input_captured_outputs\n",
      "     |  \n",
      "     |  df_input_vjps\n",
      "     |  \n",
      "     |  df_output_vjps\n",
      "     |  \n",
      "     |  f\n",
      "     |  \n",
      "     |  f_real_outputs\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Graph(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Graph\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Graph) -> str\n",
      "     |  \n",
      "     |  addInput(...)\n",
      "     |      addInput(self: torch._C.Graph) -> torch::jit::Value\n",
      "     |  \n",
      "     |  appendNode(...)\n",
      "     |      appendNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  copy(...)\n",
      "     |      copy(self: torch._C.Graph) -> torch._C.Graph\n",
      "     |  \n",
      "     |  create(...)\n",
      "     |      create(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. create(self: torch._C.Graph, arg0: str) -> torch::jit::Node\n",
      "     |      \n",
      "     |      2. create(self: torch._C.Graph, arg0: str, arg1: int) -> torch::jit::Node\n",
      "     |      \n",
      "     |      3. create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Value]) -> torch::jit::Node\n",
      "     |      \n",
      "     |      4. create(self: torch._C.Graph, arg0: str, arg1: List[torch::jit::Value], arg2: int) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createClone(...)\n",
      "     |      createClone(self: torch._C.Graph, arg0: torch::jit::Node, arg1: object) -> torch::jit::Node\n",
      "     |  \n",
      "     |  createFusionGroup(...)\n",
      "     |      createFusionGroup(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  dump_alias_db(...)\n",
      "     |      dump_alias_db(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  eraseInput(...)\n",
      "     |      eraseInput(self: torch._C.Graph, arg0: int) -> None\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Graph, kind: str, recurse: bool = True) -> List[torch::jit::Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Graph, kind: str, recurse: bool = True) -> torch::jit::Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  insertNode(...)\n",
      "     |      insertNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  lint(...)\n",
      "     |      lint(self: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  nodes(...)\n",
      "     |      nodes(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Graph) -> iterator\n",
      "     |  \n",
      "     |  param_node(...)\n",
      "     |      param_node(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  prependNode(...)\n",
      "     |      prependNode(self: torch._C.Graph, arg0: torch::jit::Node) -> torch::jit::Node\n",
      "     |  \n",
      "     |  registerOutput(...)\n",
      "     |      registerOutput(self: torch._C.Graph, arg0: torch::jit::Value) -> int\n",
      "     |  \n",
      "     |  return_node(...)\n",
      "     |      return_node(self: torch._C.Graph) -> torch::jit::Node\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class GraphExecutorState(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      GraphExecutorState\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  execution_plans\n",
      "     |  \n",
      "     |  fallback\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IODescriptor(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      IODescriptor\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class IntStorage(torch._C.IntStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      IntStorage\n",
      "     |      torch._C.IntStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.IntStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class IntTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(0, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [1, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([0, 0, 0, 1], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(1, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.any(dim=1)\n",
      "     |          tensor([1, 0, 1, 0], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrifact_with_info(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrisolve(self, LU_data, LU_pivots)\n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of dense dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(self, A)\n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(self, upper=True)\n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  potri(self, upper=True)\n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  potrs(self, u, upper=True)\n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(self, upper=True)\n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  quantize_linear(...)\n",
      "     |      quantize_linear(scale, zero_point) -> Tensor\n",
      "     |      \n",
      "     |      Quantize a float Tensor using affine quantization scheme with given scale and\n",
      "     |      zero_point.\n",
      "     |      returns the quantized Tensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of sparse dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(self, A, upper=True, transpose=False, unitriangular=False)\n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int32\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class IntType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      IntType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.IntType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class JITException(builtins.Exception)\n",
      "     |  Common base class for all non-exit exceptions.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      JITException\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class ListType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      ListType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ListType, arg0: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getElementType(...)\n",
      "     |      getElementType(self: torch._C.ListType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ofInts(...) from builtins.PyCapsule\n",
      "     |      ofInts() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ofTensors(...) from builtins.PyCapsule\n",
      "     |      ofTensors() -> torch._C.ListType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LockingLogger(LoggerBase)\n",
      "     |  Method resolution order:\n",
      "     |      LockingLogger\n",
      "     |      LoggerBase\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.LockingLogger) -> None\n",
      "     |  \n",
      "     |  get_counter_val(...)\n",
      "     |      get_counter_val(self: torch._C.LockingLogger, arg0: str) -> int\n",
      "     |  \n",
      "     |  set_aggregation_type(...)\n",
      "     |      set_aggregation_type(self: torch._C.LockingLogger, arg0: str, arg1: torch._C.AggregationType) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class LongStorage(torch._C.LongStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      LongStorage\n",
      "     |      torch._C.LongStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.LongStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class LongTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(0, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [1, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([0, 0, 0, 1], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(1, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.any(dim=1)\n",
      "     |          tensor([1, 0, 1, 0], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrifact_with_info(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrisolve(self, LU_data, LU_pivots)\n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of dense dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(self, A)\n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(self, upper=True)\n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  potri(self, upper=True)\n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  potrs(self, u, upper=True)\n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(self, upper=True)\n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  quantize_linear(...)\n",
      "     |      quantize_linear(scale, zero_point) -> Tensor\n",
      "     |      \n",
      "     |      Quantize a float Tensor using affine quantization scheme with given scale and\n",
      "     |      zero_point.\n",
      "     |      returns the quantized Tensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of sparse dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(self, A, upper=True, transpose=False, unitriangular=False)\n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int64\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class Node(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Node\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  addBlock(...)\n",
      "     |      addBlock(self: torch._C.Node) -> torch._C.Block\n",
      "     |  \n",
      "     |  addInput(...)\n",
      "     |      addInput(self: torch._C.Node, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  addOutput(...)\n",
      "     |      addOutput(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  attributeNames(...)\n",
      "     |      attributeNames(self: torch._C.Node) -> List[str]\n",
      "     |  \n",
      "     |  blocks(...)\n",
      "     |      blocks(self: torch._C.Node) -> iterator\n",
      "     |  \n",
      "     |  cconv(...)\n",
      "     |      cconv(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  copyAttributes(...)\n",
      "     |      copyAttributes(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  destroy(...)\n",
      "     |      destroy(self: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  eraseOutput(...)\n",
      "     |      eraseOutput(self: torch._C.Node, arg0: int) -> None\n",
      "     |  \n",
      "     |  f(...)\n",
      "     |      f(self: torch._C.Node, arg0: str) -> float\n",
      "     |  \n",
      "     |  f_(...)\n",
      "     |      f_(self: torch._C.Node, arg0: str, arg1: float) -> torch._C.Node\n",
      "     |  \n",
      "     |  findAllNodes(...)\n",
      "     |      findAllNodes(self: torch._C.Node, kind: str, recurse: bool = True) -> List[torch._C.Node]\n",
      "     |      \n",
      "     |      Find all nodes\n",
      "     |  \n",
      "     |  findNode(...)\n",
      "     |      findNode(self: torch._C.Node, kind: str, recurse: bool = True) -> torch._C.Node\n",
      "     |      \n",
      "     |      Find Node\n",
      "     |  \n",
      "     |  fs(...)\n",
      "     |      fs(self: torch._C.Node, arg0: str) -> List[float]\n",
      "     |  \n",
      "     |  fs_(...)\n",
      "     |      fs_(self: torch._C.Node, arg0: str, arg1: List[float]) -> torch._C.Node\n",
      "     |  \n",
      "     |  g(...)\n",
      "     |      g(self: torch._C.Node, arg0: str) -> torch._C.Graph\n",
      "     |  \n",
      "     |  g_(...)\n",
      "     |      g_(self: torch._C.Node, arg0: str, arg1: torch._C.Graph) -> torch._C.Node\n",
      "     |  \n",
      "     |  getSourceLocation(...)\n",
      "     |      getSourceLocation(self: torch._C.Node) -> object\n",
      "     |  \n",
      "     |  gs(...)\n",
      "     |      gs(self: torch._C.Node, arg0: str) -> List[torch._C.Graph]\n",
      "     |  \n",
      "     |  gs_(...)\n",
      "     |      gs_(self: torch._C.Node, arg0: str, arg1: List[torch._C.Graph]) -> torch._C.Node\n",
      "     |  \n",
      "     |  hasAttribute(...)\n",
      "     |      hasAttribute(self: torch._C.Node, arg0: str) -> bool\n",
      "     |  \n",
      "     |  hasAttributes(...)\n",
      "     |      hasAttributes(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  hasMultipleOutputs(...)\n",
      "     |      hasMultipleOutputs(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  hasUses(...)\n",
      "     |      hasUses(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  i(...)\n",
      "     |      i(self: torch._C.Node, arg0: str) -> int\n",
      "     |  \n",
      "     |  i_(...)\n",
      "     |      i_(self: torch._C.Node, arg0: str, arg1: int) -> torch._C.Node\n",
      "     |  \n",
      "     |  input(...)\n",
      "     |      input(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  inputs(...)\n",
      "     |      inputs(self: torch._C.Node) -> iterator\n",
      "     |  \n",
      "     |  inputsAt(...)\n",
      "     |      inputsAt(self: torch._C.Node, arg0: int) -> torch._C.Value\n",
      "     |  \n",
      "     |  insertAfter(...)\n",
      "     |      insertAfter(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  insertBefore(...)\n",
      "     |      insertBefore(self: torch._C.Node, arg0: torch._C.Node) -> torch._C.Node\n",
      "     |  \n",
      "     |  is(...)\n",
      "     |      is(self: torch._C.Node, arg0: str) -> List[int]\n",
      "     |  \n",
      "     |  isNondeterministic(...)\n",
      "     |      isNondeterministic(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  is_(...)\n",
      "     |      is_(self: torch._C.Node, arg0: str, arg1: List[int]) -> torch._C.Node\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Node) -> Symbol\n",
      "     |  \n",
      "     |  kindOf(...)\n",
      "     |      kindOf(self: torch._C.Node, arg0: str) -> AttributeKind\n",
      "     |  \n",
      "     |  moveAfter(...)\n",
      "     |      moveAfter(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  moveBefore(...)\n",
      "     |      moveBefore(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  mustBeNone(...)\n",
      "     |      mustBeNone(self: torch._C.Node) -> bool\n",
      "     |  \n",
      "     |  output(...)\n",
      "     |      output(self: torch._C.Node) -> torch._C.Value\n",
      "     |  \n",
      "     |  outputs(...)\n",
      "     |      outputs(self: torch._C.Node) -> iterator\n",
      "     |  \n",
      "     |  outputsAt(...)\n",
      "     |      outputsAt(self: torch._C.Node, arg0: int) -> torch._C.Value\n",
      "     |  \n",
      "     |  outputsSize(...)\n",
      "     |      outputsSize(self: torch._C.Node) -> int\n",
      "     |  \n",
      "     |  pyname(...)\n",
      "     |      pyname(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  pyobj(...)\n",
      "     |      pyobj(self: torch._C.Node) -> object\n",
      "     |  \n",
      "     |  removeAllInputs(...)\n",
      "     |      removeAllInputs(self: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  removeAttribute(...)\n",
      "     |      removeAttribute(self: torch._C.Node, arg0: str) -> torch._C.Node\n",
      "     |  \n",
      "     |  removeInput(...)\n",
      "     |      removeInput(self: torch._C.Node, arg0: int) -> None\n",
      "     |  \n",
      "     |  replaceAllUsesWith(...)\n",
      "     |      replaceAllUsesWith(self: torch._C.Node, arg0: torch._C.Node) -> None\n",
      "     |  \n",
      "     |  replaceInput(...)\n",
      "     |      replaceInput(self: torch._C.Node, arg0: int, arg1: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  replaceInputWith(...)\n",
      "     |      replaceInputWith(self: torch._C.Node, arg0: torch._C.Value, arg1: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  s(...)\n",
      "     |      s(self: torch._C.Node, arg0: str) -> str\n",
      "     |  \n",
      "     |  s_(...)\n",
      "     |      s_(self: torch._C.Node, arg0: str, arg1: str) -> torch._C.Node\n",
      "     |  \n",
      "     |  scalar_args(...)\n",
      "     |      scalar_args(self: torch._C.Node) -> list\n",
      "     |  \n",
      "     |  scopeName(...)\n",
      "     |      scopeName(self: torch._C.Node) -> str\n",
      "     |  \n",
      "     |  ss(...)\n",
      "     |      ss(self: torch._C.Node, arg0: str) -> List[str]\n",
      "     |  \n",
      "     |  ss_(...)\n",
      "     |      ss_(self: torch._C.Node, arg0: str, arg1: List[str]) -> torch._C.Node\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t(self: torch._C.Node, arg0: str) -> at::Tensor\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_(self: torch._C.Node, arg0: str, arg1: torch::autograd::Variable) -> torch._C.Node\n",
      "     |  \n",
      "     |  ts(...)\n",
      "     |      ts(self: torch._C.Node, arg0: str) -> List[torch::autograd::Variable]\n",
      "     |  \n",
      "     |  ts_(...)\n",
      "     |      ts_(self: torch._C.Node, arg0: str, arg1: List[torch::autograd::Variable]) -> torch._C.Node\n",
      "     |  \n",
      "     |  z(...)\n",
      "     |      z(self: torch._C.Node, arg0: str) -> at::Tensor\n",
      "     |  \n",
      "     |  z_(...)\n",
      "     |      z_(self: torch._C.Node, arg0: str, arg1: at::Tensor) -> torch._C.Node\n",
      "     |  \n",
      "     |  zs(...)\n",
      "     |      zs(self: torch._C.Node, arg0: str) -> List[at::Tensor]\n",
      "     |  \n",
      "     |  zs_(...)\n",
      "     |      zs_(self: torch._C.Node, arg0: str, arg1: List[at::Tensor]) -> torch._C.Node\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class NoopLogger(LoggerBase)\n",
      "     |  Method resolution order:\n",
      "     |      NoopLogger\n",
      "     |      LoggerBase\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.NoopLogger) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class NumberType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      NumberType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.NumberType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class OptionalType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      OptionalType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.OptionalType, arg0: torch._C.Type) -> None\n",
      "     |  \n",
      "     |  getElementType(...)\n",
      "     |      getElementType(self: torch._C.OptionalType) -> torch._C.Type\n",
      "     |  \n",
      "     |  ofTensor(...) from builtins.PyCapsule\n",
      "     |      ofTensor() -> torch._C.OptionalType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PyTorchFileReader(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      PyTorchFileReader\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.PyTorchFileReader, arg0: str) -> None\n",
      "     |  \n",
      "     |  get_record(...)\n",
      "     |      get_record(self: torch._C.PyTorchFileReader, arg0: str) -> bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PyTorchFileWriter(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      PyTorchFileWriter\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.PyTorchFileWriter, arg0: str) -> None\n",
      "     |  \n",
      "     |  write_end_of_file(...)\n",
      "     |      write_end_of_file(self: torch._C.PyTorchFileWriter) -> None\n",
      "     |  \n",
      "     |  write_record(...)\n",
      "     |      write_record(self: torch._C.PyTorchFileWriter, arg0: str, arg1: str, arg2: int) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptMethod(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptMethod\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(...)\n",
      "     |      __call__(*args, **kwargs) -> object\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  graph_for = _graph_for(self, *args, **kwargs)\n",
      "     |  \n",
      "     |  initial_ivalues(...)\n",
      "     |      initial_ivalues(self: torch._C.ScriptMethod) -> List[at::Tensor]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  graph\n",
      "     |  \n",
      "     |  schema\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ScriptModule(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      ScriptModule\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.ScriptModule) -> None\n",
      "     |  \n",
      "     |  apply(...)\n",
      "     |      apply(self: torch._C.ScriptModule, arg0: Callable[[torch._C.ScriptModule], None]) -> None\n",
      "     |  \n",
      "     |  clone_method(...)\n",
      "     |      clone_method(self: torch._C.ScriptModule, arg0: torch._C.ScriptModule, arg1: str) -> None\n",
      "     |  \n",
      "     |  get_debug_state(...)\n",
      "     |      get_debug_state(self: torch._C.ScriptModule) -> torch._C.GraphExecutorState\n",
      "     |  \n",
      "     |  save(...)\n",
      "     |      save(self: torch._C.ScriptModule, filename: str, _extra_files: torch._C.ExtraFilesMap = ExtraFilesMap{}) -> None\n",
      "     |  \n",
      "     |  save_to_buffer(...)\n",
      "     |      save_to_buffer(self: torch._C.ScriptModule, _extra_files: torch._C.ExtraFilesMap = ExtraFilesMap{}) -> bytes\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  code\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class ShortStorage(torch._C.ShortStorageBase, torch.storage._StorageBase)\n",
      "     |  Method resolution order:\n",
      "     |      ShortStorage\n",
      "     |      torch._C.ShortStorageBase\n",
      "     |      torch.storage._StorageBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |  \n",
      "     |  is_pinned(...)\n",
      "     |  \n",
      "     |  is_shared(...)\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  from_buffer(...)\n",
      "     |  \n",
      "     |  from_file(...)\n",
      "     |      from_file(filename, shared=False, size=0) -> Storage\n",
      "     |      \n",
      "     |      If `shared` is `True`, then memory is shared between all processes.\n",
      "     |      All changes are written to the file. If `shared` is `False`, then the changes on\n",
      "     |      the storage do not affect the file.\n",
      "     |      \n",
      "     |      `size` is the number of elements in the storage. If `shared` is `False`,\n",
      "     |      then the file must contain at least `size * sizeof(Type)` bytes\n",
      "     |      (`Type` is the type of storage). If `shared` is `True` the file will be\n",
      "     |      created if needed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          filename (str): file name to map\n",
      "     |          shared (bool): whether to share memory\n",
      "     |          size (int): number of elements in the storage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C.ShortStorageBase:\n",
      "     |  \n",
      "     |  device\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __sizeof__(self)\n",
      "     |      __sizeof__() -> int\n",
      "     |      size of object in memory, in bytes\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  bool(self)\n",
      "     |      Casts this storage to bool type\n",
      "     |  \n",
      "     |  byte(self)\n",
      "     |      Casts this storage to byte type\n",
      "     |  \n",
      "     |  char(self)\n",
      "     |      Casts this storage to char type\n",
      "     |  \n",
      "     |  clone(self)\n",
      "     |      Returns a copy of this storage\n",
      "     |  \n",
      "     |  cpu(self)\n",
      "     |      Returns a CPU copy of this storage if it's not already on the CPU\n",
      "     |  \n",
      "     |  cuda = _cuda(self, device=None, non_blocking=False, **kwargs)\n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device, then\n",
      "     |      no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (int): The destination GPU id. Defaults to the current device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host. Otherwise,\n",
      "     |              the argument has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument.\n",
      "     |  \n",
      "     |  double(self)\n",
      "     |      Casts this storage to double type\n",
      "     |  \n",
      "     |  float(self)\n",
      "     |      Casts this storage to float type\n",
      "     |  \n",
      "     |  half(self)\n",
      "     |      Casts this storage to half type\n",
      "     |  \n",
      "     |  int(self)\n",
      "     |      Casts this storage to int type\n",
      "     |  \n",
      "     |  long(self)\n",
      "     |      Casts this storage to long type\n",
      "     |  \n",
      "     |  pin_memory(self)\n",
      "     |      Copies the storage to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op for storages already in shared memory and for CUDA\n",
      "     |      storages, which do not need to be moved for sharing across processes.\n",
      "     |      Storages in shared memory cannot be resized.\n",
      "     |      \n",
      "     |      Returns: self\n",
      "     |  \n",
      "     |  short(self)\n",
      "     |      Casts this storage to short type\n",
      "     |  \n",
      "     |  tolist(self)\n",
      "     |      Returns a list containing the elements of this storage\n",
      "     |  \n",
      "     |  type = _type(self, dtype=None, non_blocking=False, **kwargs)\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from torch.storage._StorageBase:\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "    \n",
      "    class ShortTensor(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from tensortype\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(0, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [1, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([0, 0, 0, 1], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(1, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.any(dim=1)\n",
      "     |          tensor([1, 0, 1, 0], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  btrifact(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrifact_with_info(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrisolve(self, LU_data, LU_pivots)\n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of dense dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  gesv(self, A)\n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  potrf(self, upper=True)\n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  potri(self, upper=True)\n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  potrs(self, u, upper=True)\n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  pstrf(self, upper=True)\n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  quantize_linear(...)\n",
      "     |      quantize_linear(scale, zero_point) -> Tensor\n",
      "     |      \n",
      "     |      Quantize a float Tensor using affine quantization scheme with given scale and\n",
      "     |      zero_point.\n",
      "     |      returns the quantized Tensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of sparse dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trtrs(self, A, upper=True, transpose=False, unitriangular=False)\n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  dtype = torch.int16\n",
      "     |  \n",
      "     |  is_cuda = False\n",
      "     |  \n",
      "     |  is_sparse = False\n",
      "     |  \n",
      "     |  layout = torch.strided\n",
      "    \n",
      "    class Size(builtins.tuple)\n",
      "     |  tuple() -> empty tuple\n",
      "     |  tuple(iterable) -> tuple initialized from iterable's items\n",
      "     |  \n",
      "     |  If the argument is a tuple, the return value is the same object.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Size\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getnewargs__(...)\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      T.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class StringType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      StringType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.StringType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Tensor(torch._C._TensorBase)\n",
      "     |  Method resolution order:\n",
      "     |      Tensor\n",
      "     |      torch._C._TensorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  __array__(self, dtype=None)\n",
      "     |  \n",
      "     |  __array_wrap__(self, array)\n",
      "     |      # Wrap Numpy array again in a suitable tensor when done, to support e.g.\n",
      "     |      # `numpy.sin(tensor) -> tensor` or `numpy.greater(tensor, 0) -> ByteTensor`\n",
      "     |  \n",
      "     |  __contains__(self, element)\n",
      "     |      Check if `element` is present in tensor\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          element (Tensor or scalar): element to be checked\n",
      "     |              for presence in current tensor\"\n",
      "     |  \n",
      "     |  __deepcopy__(self, memo)\n",
      "     |  \n",
      "     |  __dir__(self)\n",
      "     |      __dir__() -> list\n",
      "     |      default dir() implementation\n",
      "     |  \n",
      "     |  __eq__ = eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |  \n",
      "     |  __format__(self, format_spec)\n",
      "     |      default object formatter\n",
      "     |  \n",
      "     |  __ge__ = ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  __gt__ = gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ipow__(self, other)\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __itruediv__ = __idiv__(...)\n",
      "     |  \n",
      "     |  __le__ = le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__ = lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  __ne__ = ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  __neg__ = neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  __pow__ = pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __reduce_ex__(self, proto)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __reversed__(self)\n",
      "     |      Reverses the tensor along dimension 0.\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |  \n",
      "     |  __rpow__(self, other)\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |  \n",
      "     |  __rtruediv__ = __rdiv__(self, other)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  backward(self, gradient=None, retain_graph=None, create_graph=False)\n",
      "     |      Computes the gradient of current tensor w.r.t. graph leaves.\n",
      "     |      \n",
      "     |      The graph is differentiated using the chain rule. If the tensor is\n",
      "     |      non-scalar (i.e. its data has more than one element) and requires\n",
      "     |      gradient, the function additionally requires specifying ``gradient``.\n",
      "     |      It should be a tensor of matching type and location, that contains\n",
      "     |      the gradient of the differentiated function w.r.t. ``self``.\n",
      "     |      \n",
      "     |      This function accumulates gradients in the leaves - you might need to\n",
      "     |      zero them before calling it.\n",
      "     |      \n",
      "     |      Arguments:\n",
      "     |          gradient (Tensor or None): Gradient w.r.t. the\n",
      "     |              tensor. If it is a tensor, it will be automatically converted\n",
      "     |              to a Tensor that does not require grad unless ``create_graph`` is True.\n",
      "     |              None values can be specified for scalar Tensors or ones that\n",
      "     |              don't require grad. If a None value would be acceptable then\n",
      "     |              this argument is optional.\n",
      "     |          retain_graph (bool, optional): If ``False``, the graph used to compute\n",
      "     |              the grads will be freed. Note that in nearly all cases setting\n",
      "     |              this option to True is not needed and often can be worked around\n",
      "     |              in a much more efficient way. Defaults to the value of\n",
      "     |              ``create_graph``.\n",
      "     |          create_graph (bool, optional): If ``True``, graph of the derivative will\n",
      "     |              be constructed, allowing to compute higher order derivative\n",
      "     |              products. Defaults to ``False``.\n",
      "     |  \n",
      "     |  btrifact(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrifact_with_info(self, pivot=True)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  btrisolve(self, LU_data, LU_pivots)\n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  detach(...)\n",
      "     |      Returns a new Tensor, detached from the current graph.\n",
      "     |      \n",
      "     |      The result will never require gradient.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |        Returned Tensor shares the same storage with the original one.\n",
      "     |        In-place modifications on either of them will be seen, and may trigger\n",
      "     |        errors in correctness checks.\n",
      "     |        IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n",
      "     |        (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n",
      "     |        also update the original tensor. Now, these in-place changes will not update the\n",
      "     |        original tensor anymore, and will instead trigger an error.\n",
      "     |        For sparse tensors:\n",
      "     |        In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n",
      "     |        returned tensor will not update the original tensor anymore, and will instead\n",
      "     |        trigger an error.\n",
      "     |  \n",
      "     |  detach_(...)\n",
      "     |      Detaches the Tensor from the graph that created it, making it a leaf.\n",
      "     |      Views cannot be detached in-place.\n",
      "     |  \n",
      "     |  gesv(self, A)\n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  is_pinned(self)\n",
      "     |      Returns true if this tensor resides in pinned memory\n",
      "     |  \n",
      "     |  is_shared(self)\n",
      "     |      Checks if tensor is in shared memory.\n",
      "     |      \n",
      "     |      This is always ``True`` for CUDA tensors.\n",
      "     |  \n",
      "     |  lu(self, pivot=True, get_infos=False)\n",
      "     |      See :func:`torch.lu`\n",
      "     |  \n",
      "     |  norm(self, p='fro', dim=None, keepdim=False, dtype=None)\n",
      "     |      See :func:`torch.norm`\n",
      "     |  \n",
      "     |  potrf(self, upper=True)\n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  potri(self, upper=True)\n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  potrs(self, u, upper=True)\n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  pstrf(self, upper=True)\n",
      "     |      See :func:`torch.pstrf`\n",
      "     |  \n",
      "     |  register_hook(self, hook)\n",
      "     |      Registers a backward hook.\n",
      "     |      \n",
      "     |      The hook will be called every time a gradient with respect to the\n",
      "     |      Tensor is computed. The hook should have the following signature::\n",
      "     |      \n",
      "     |          hook(grad) -> Tensor or None\n",
      "     |      \n",
      "     |      \n",
      "     |      The hook should not modify its argument, but it can optionally return\n",
      "     |      a new gradient which will be used in place of :attr:`grad`.\n",
      "     |      \n",
      "     |      This function returns a handle with a method ``handle.remove()``\n",
      "     |      that removes the hook from the module.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> v = torch.tensor([0., 0., 0.], requires_grad=True)\n",
      "     |          >>> h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
      "     |          >>> v.backward(torch.tensor([1., 2., 3.]))\n",
      "     |          >>> v.grad\n",
      "     |      \n",
      "     |           2\n",
      "     |           4\n",
      "     |           6\n",
      "     |          [torch.FloatTensor of size (3,)]\n",
      "     |      \n",
      "     |          >>> h.remove()  # removes the hook\n",
      "     |  \n",
      "     |  reinforce(self, reward)\n",
      "     |  \n",
      "     |  resize(self, *sizes)\n",
      "     |  \n",
      "     |  resize_as(self, tensor)\n",
      "     |  \n",
      "     |  retain_grad(self)\n",
      "     |      Enables .grad attribute for non-leaf Tensors.\n",
      "     |  \n",
      "     |  share_memory_(self)\n",
      "     |      Moves the underlying storage to shared memory.\n",
      "     |      \n",
      "     |      This is a no-op if the underlying storage is already in shared memory\n",
      "     |      and for CUDA tensors. Tensors in shared memory cannot be resized.\n",
      "     |  \n",
      "     |  split(self, split_size, dim=0)\n",
      "     |      See :func:`torch.split`\n",
      "     |  \n",
      "     |  stft(self, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=True)\n",
      "     |      See :func:`torch.stft`\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |        This function changed signature at version 0.4.1. Calling with\n",
      "     |        the previous signature may cause error or return incorrect result.\n",
      "     |  \n",
      "     |  trtrs(self, A, upper=True, transpose=False, unitriangular=False)\n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  unique(self, sorted=True, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Returns the unique elements of the input tensor.\n",
      "     |      \n",
      "     |      See :func:`torch.unique`\n",
      "     |  \n",
      "     |  unique_consecutive(self, return_inverse=False, return_counts=False, dim=None)\n",
      "     |      Eliminates all but the first element from every consecutive group of equivalent elements.\n",
      "     |      \n",
      "     |      See :func:`torch.unique_consecutive`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __cuda_array_interface__\n",
      "     |      Array view description for cuda tensors.\n",
      "     |      \n",
      "     |      See:\n",
      "     |      https://numba.pydata.org/numba-doc/latest/cuda/cuda_array_interface.html\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __array_priority__ = 1000\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  __add__(...)\n",
      "     |  \n",
      "     |  __and__(...)\n",
      "     |  \n",
      "     |  __bool__(...)\n",
      "     |  \n",
      "     |  __delitem__(self, key, /)\n",
      "     |      Delete self[key].\n",
      "     |  \n",
      "     |  __div__(...)\n",
      "     |  \n",
      "     |  __float__(...)\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __iadd__(...)\n",
      "     |  \n",
      "     |  __iand__(...)\n",
      "     |  \n",
      "     |  __idiv__(...)\n",
      "     |  \n",
      "     |  __ilshift__(...)\n",
      "     |  \n",
      "     |  __imul__(...)\n",
      "     |  \n",
      "     |  __index__(...)\n",
      "     |  \n",
      "     |  __int__(...)\n",
      "     |  \n",
      "     |  __invert__(...)\n",
      "     |  \n",
      "     |  __ior__(...)\n",
      "     |  \n",
      "     |  __irshift__(...)\n",
      "     |  \n",
      "     |  __isub__(...)\n",
      "     |  \n",
      "     |  __ixor__(...)\n",
      "     |  \n",
      "     |  __long__(...)\n",
      "     |  \n",
      "     |  __lshift__(...)\n",
      "     |  \n",
      "     |  __matmul__(...)\n",
      "     |  \n",
      "     |  __mod__(...)\n",
      "     |  \n",
      "     |  __mul__(...)\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __nonzero__(...)\n",
      "     |  \n",
      "     |  __or__(...)\n",
      "     |  \n",
      "     |  __radd__(...)\n",
      "     |  \n",
      "     |  __rmul__(...)\n",
      "     |  \n",
      "     |  __rshift__(...)\n",
      "     |  \n",
      "     |  __setitem__(self, key, value, /)\n",
      "     |      Set self[key] to value.\n",
      "     |  \n",
      "     |  __sub__(...)\n",
      "     |  \n",
      "     |  __truediv__(...)\n",
      "     |  \n",
      "     |  __xor__(...)\n",
      "     |  \n",
      "     |  abs(...)\n",
      "     |      abs() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.abs`\n",
      "     |  \n",
      "     |  abs_(...)\n",
      "     |      abs_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.abs`\n",
      "     |  \n",
      "     |  acos(...)\n",
      "     |      acos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.acos`\n",
      "     |  \n",
      "     |  acos_(...)\n",
      "     |      acos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.acos`\n",
      "     |  \n",
      "     |  add(...)\n",
      "     |      add(value) -> Tensor\n",
      "     |      add(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.add`\n",
      "     |  \n",
      "     |  add_(...)\n",
      "     |      add_(value) -> Tensor\n",
      "     |      add_(value=1, other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.add`\n",
      "     |  \n",
      "     |  addbmm(...)\n",
      "     |      addbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addbmm`\n",
      "     |  \n",
      "     |  addbmm_(...)\n",
      "     |      addbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addbmm`\n",
      "     |  \n",
      "     |  addcdiv(...)\n",
      "     |      addcdiv(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcdiv`\n",
      "     |  \n",
      "     |  addcdiv_(...)\n",
      "     |      addcdiv_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcdiv`\n",
      "     |  \n",
      "     |  addcmul(...)\n",
      "     |      addcmul(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addcmul`\n",
      "     |  \n",
      "     |  addcmul_(...)\n",
      "     |      addcmul_(value=1, tensor1, tensor2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addcmul`\n",
      "     |  \n",
      "     |  addmm(...)\n",
      "     |      addmm(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmm`\n",
      "     |  \n",
      "     |  addmm_(...)\n",
      "     |      addmm_(beta=1, alpha=1, mat1, mat2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmm`\n",
      "     |  \n",
      "     |  addmv(...)\n",
      "     |      addmv(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addmv`\n",
      "     |  \n",
      "     |  addmv_(...)\n",
      "     |      addmv_(beta=1, alpha=1, mat, vec) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addmv`\n",
      "     |  \n",
      "     |  addr(...)\n",
      "     |      addr(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.addr`\n",
      "     |  \n",
      "     |  addr_(...)\n",
      "     |      addr_(beta=1, alpha=1, vec1, vec2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.addr`\n",
      "     |  \n",
      "     |  all(...)\n",
      "     |      .. function:: all() -> bool\n",
      "     |      \n",
      "     |      Returns True if all elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.all()\n",
      "     |          tensor(0, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: all(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if all elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [1, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.all(dim=1)\n",
      "     |          tensor([0, 0, 0, 1], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  allclose(...)\n",
      "     |      allclose(other, rtol=1e-05, atol=1e-08, equal_nan=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.allclose`\n",
      "     |  \n",
      "     |  any(...)\n",
      "     |      .. function:: any() -> bool\n",
      "     |      \n",
      "     |      Returns True if any elements in the tensor are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 3).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[0, 0, 1]], dtype=torch.uint8)\n",
      "     |          >>> a.any()\n",
      "     |          tensor(1, dtype=torch.uint8)\n",
      "     |      \n",
      "     |      .. function:: any(dim, keepdim=False, out=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns True if any elements in each row of the tensor in the given\n",
      "     |      dimension :attr:`dim` are non-zero, False otherwise.\n",
      "     |      \n",
      "     |      If :attr:`keepdim` is ``True``, the output tensor is of the same size as\n",
      "     |      :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\n",
      "     |      Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "     |      in the output tensor having 1 fewer dimension than :attr:`input`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to reduce\n",
      "     |          keepdim (bool): whether the output tensor has :attr:`dim` retained or not\n",
      "     |          out (Tensor, optional): the output tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(4, 2).byte() % 2\n",
      "     |          >>> a\n",
      "     |          tensor([[1, 0],\n",
      "     |                  [0, 0],\n",
      "     |                  [0, 1],\n",
      "     |                  [0, 0]], dtype=torch.uint8)\n",
      "     |          >>> a.any(dim=1)\n",
      "     |          tensor([1, 0, 1, 0], dtype=torch.uint8)\n",
      "     |  \n",
      "     |  apply_(...)\n",
      "     |      apply_(callable) -> Tensor\n",
      "     |      \n",
      "     |      Applies the function :attr:`callable` to each element in the tensor, replacing\n",
      "     |      each element with the value returned by :attr:`callable`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          This function only works with CPU tensors and should not be used in code\n",
      "     |          sections that require high performance.\n",
      "     |  \n",
      "     |  argmax(...)\n",
      "     |      argmax(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmax`\n",
      "     |  \n",
      "     |  argmin(...)\n",
      "     |      argmin(dim=None, keepdim=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.argmin`\n",
      "     |  \n",
      "     |  argsort(...)\n",
      "     |      argsort(dim=-1, descending=False) -> LongTensor\n",
      "     |      \n",
      "     |      See :func: `torch.argsort`\n",
      "     |  \n",
      "     |  as_strided(...)\n",
      "     |  \n",
      "     |  as_strided_(...)\n",
      "     |  \n",
      "     |  asin(...)\n",
      "     |      asin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.asin`\n",
      "     |  \n",
      "     |  asin_(...)\n",
      "     |      asin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.asin`\n",
      "     |  \n",
      "     |  atan(...)\n",
      "     |      atan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan`\n",
      "     |  \n",
      "     |  atan2(...)\n",
      "     |      atan2(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.atan2`\n",
      "     |  \n",
      "     |  atan2_(...)\n",
      "     |      atan2_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan2`\n",
      "     |  \n",
      "     |  atan_(...)\n",
      "     |      atan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.atan`\n",
      "     |  \n",
      "     |  baddbmm(...)\n",
      "     |      baddbmm(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.baddbmm`\n",
      "     |  \n",
      "     |  baddbmm_(...)\n",
      "     |      baddbmm_(beta=1, alpha=1, batch1, batch2) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.baddbmm`\n",
      "     |  \n",
      "     |  bernoulli(...)\n",
      "     |      bernoulli(*, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Returns a result tensor where each :math:`\\texttt{result[i]}` is independently\n",
      "     |      sampled from :math:`\\text{Bernoulli}(\\texttt{self[i]})`. :attr:`self` must have\n",
      "     |      floating point ``dtype``, and the result will have the same ``dtype``.\n",
      "     |      \n",
      "     |      See :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bernoulli_(...)\n",
      "     |      .. function:: bernoulli_(p=0.5, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          Fills each location of :attr:`self` with an independent sample from\n",
      "     |          :math:`\\text{Bernoulli}(\\texttt{p})`. :attr:`self` can have integral\n",
      "     |          ``dtype``.\n",
      "     |      \n",
      "     |      .. function:: bernoulli_(p_tensor, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |          :attr:`p_tensor` should be a tensor containing probabilities to be used for\n",
      "     |          drawing the binary random number.\n",
      "     |      \n",
      "     |          The :math:`\\text{i}^{th}` element of :attr:`self` tensor will be set to a\n",
      "     |          value sampled from :math:`\\text{Bernoulli}(\\texttt{p\\_tensor[i]})`.\n",
      "     |      \n",
      "     |          :attr:`self` can have integral ``dtype``, but :attr:`p_tensor` must have\n",
      "     |          floating point ``dtype``.\n",
      "     |      \n",
      "     |      See also :meth:`~Tensor.bernoulli` and :func:`torch.bernoulli`\n",
      "     |  \n",
      "     |  bincount(...)\n",
      "     |      bincount(weights=None, minlength=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bincount`\n",
      "     |  \n",
      "     |  bmm(...)\n",
      "     |      bmm(batch2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.bmm`\n",
      "     |  \n",
      "     |  byte(...)\n",
      "     |      byte() -> Tensor\n",
      "     |      \n",
      "     |      ``self.byte()`` is equivalent to ``self.to(torch.uint8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cauchy_(...)\n",
      "     |      cauchy_(median=0, sigma=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills the tensor with numbers drawn from the Cauchy distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{\\pi} \\dfrac{\\sigma}{(x - \\text{median})^2 + \\sigma^2}\n",
      "     |  \n",
      "     |  ceil(...)\n",
      "     |      ceil() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ceil`\n",
      "     |  \n",
      "     |  ceil_(...)\n",
      "     |      ceil_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ceil`\n",
      "     |  \n",
      "     |  char(...)\n",
      "     |      char() -> Tensor\n",
      "     |      \n",
      "     |      ``self.char()`` is equivalent to ``self.to(torch.int8)``. See :func:`to`.\n",
      "     |  \n",
      "     |  cholesky(...)\n",
      "     |      cholesky(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky`\n",
      "     |  \n",
      "     |  cholesky_inverse(...)\n",
      "     |      cholesky_inverse(upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_inverse`\n",
      "     |  \n",
      "     |  cholesky_solve(...)\n",
      "     |      cholesky_solve(input2, upper=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cholesky_solve`\n",
      "     |  \n",
      "     |  chunk(...)\n",
      "     |      chunk(chunks, dim=0) -> List of Tensors\n",
      "     |      \n",
      "     |      See :func:`torch.chunk`\n",
      "     |  \n",
      "     |  clamp(...)\n",
      "     |      clamp(min, max) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.clamp`\n",
      "     |  \n",
      "     |  clamp_(...)\n",
      "     |      clamp_(min, max) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.clamp`\n",
      "     |  \n",
      "     |  clamp_max(...)\n",
      "     |  \n",
      "     |  clamp_max_(...)\n",
      "     |  \n",
      "     |  clamp_min(...)\n",
      "     |  \n",
      "     |  clamp_min_(...)\n",
      "     |  \n",
      "     |  clone(...)\n",
      "     |      clone() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of the :attr:`self` tensor. The copy has the same size and data\n",
      "     |      type as :attr:`self`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          Unlike `copy_()`, this function is recorded in the computation graph. Gradients\n",
      "     |          propagating to the cloned tensor will propagate to the original tensor.\n",
      "     |  \n",
      "     |  coalesce(...)\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous() -> Tensor\n",
      "     |      \n",
      "     |      Returns a contiguous tensor containing the same data as :attr:`self` tensor. If\n",
      "     |      :attr:`self` tensor is contiguous, this function returns the :attr:`self`\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  copy_(...)\n",
      "     |      copy_(src, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`src` into :attr:`self` tensor and returns\n",
      "     |      :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`src` tensor must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the :attr:`self` tensor. It may be of a different data type or reside on a\n",
      "     |      different device.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          src (Tensor): the source tensor to copy from\n",
      "     |          non_blocking (bool): if ``True`` and this copy is between CPU and GPU,\n",
      "     |              the copy may occur asynchronously with respect to the host. For other\n",
      "     |              cases, this argument has no effect.\n",
      "     |  \n",
      "     |  cos(...)\n",
      "     |      cos() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cos`\n",
      "     |  \n",
      "     |  cos_(...)\n",
      "     |      cos_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cos`\n",
      "     |  \n",
      "     |  cosh(...)\n",
      "     |      cosh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cosh`\n",
      "     |  \n",
      "     |  cosh_(...)\n",
      "     |      cosh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.cosh`\n",
      "     |  \n",
      "     |  cpu(...)\n",
      "     |      cpu() -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CPU memory.\n",
      "     |      \n",
      "     |      If this object is already in CPU memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |  \n",
      "     |  cross(...)\n",
      "     |      cross(other, dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cross`\n",
      "     |  \n",
      "     |  cuda(...)\n",
      "     |      cuda(device=None, non_blocking=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a copy of this object in CUDA memory.\n",
      "     |      \n",
      "     |      If this object is already in CUDA memory and on the correct device,\n",
      "     |      then no copy is performed and the original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          device (:class:`torch.device`): The destination GPU device.\n",
      "     |              Defaults to the current CUDA device.\n",
      "     |          non_blocking (bool): If ``True`` and the source is in pinned memory,\n",
      "     |              the copy will be asynchronous with respect to the host.\n",
      "     |              Otherwise, the argument has no effect. Default: ``False``.\n",
      "     |  \n",
      "     |  cumprod(...)\n",
      "     |      cumprod(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumprod`\n",
      "     |  \n",
      "     |  cumsum(...)\n",
      "     |      cumsum(dim, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.cumsum`\n",
      "     |  \n",
      "     |  data_ptr(...)\n",
      "     |      data_ptr() -> int\n",
      "     |      \n",
      "     |      Returns the address of the first element of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dense_dim(...)\n",
      "     |      dense_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of dense dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.sparse_dim`.\n",
      "     |  \n",
      "     |  dequantize(...)\n",
      "     |      dequantize() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor, dequantize it and return the dequantized float Tensor.\n",
      "     |  \n",
      "     |  det(...)\n",
      "     |      det() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.det`\n",
      "     |  \n",
      "     |  diag(...)\n",
      "     |      diag(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag`\n",
      "     |  \n",
      "     |  diag_embed(...)\n",
      "     |      diag_embed(offset=0, dim1=-2, dim2=-1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diag_embed`\n",
      "     |  \n",
      "     |  diagflat(...)\n",
      "     |      diagflat(diagonal=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagflat`\n",
      "     |  \n",
      "     |  diagonal(...)\n",
      "     |      diagonal(offset=0, dim1=0, dim2=1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.diagonal`\n",
      "     |  \n",
      "     |  digamma(...)\n",
      "     |      digamma() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.digamma`\n",
      "     |  \n",
      "     |  digamma_(...)\n",
      "     |      digamma_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.digamma`\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim() -> int\n",
      "     |      \n",
      "     |      Returns the number of dimensions of :attr:`self` tensor.\n",
      "     |  \n",
      "     |  dist(...)\n",
      "     |      dist(other, p=2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dist`\n",
      "     |  \n",
      "     |  div(...)\n",
      "     |      div(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.div`\n",
      "     |  \n",
      "     |  div_(...)\n",
      "     |      div_(value) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.div`\n",
      "     |  \n",
      "     |  dot(...)\n",
      "     |      dot(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.dot`\n",
      "     |  \n",
      "     |  double(...)\n",
      "     |      double() -> Tensor\n",
      "     |      \n",
      "     |      ``self.double()`` is equivalent to ``self.to(torch.float64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  eig(...)\n",
      "     |      eig(eigenvectors=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.eig`\n",
      "     |  \n",
      "     |  element_size(...)\n",
      "     |      element_size() -> int\n",
      "     |      \n",
      "     |      Returns the size in bytes of an individual element.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.tensor([]).element_size()\n",
      "     |          4\n",
      "     |          >>> torch.tensor([], dtype=torch.uint8).element_size()\n",
      "     |          1\n",
      "     |  \n",
      "     |  eq(...)\n",
      "     |      eq(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.eq`\n",
      "     |  \n",
      "     |  eq_(...)\n",
      "     |      eq_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.eq`\n",
      "     |  \n",
      "     |  equal(...)\n",
      "     |      equal(other) -> bool\n",
      "     |      \n",
      "     |      See :func:`torch.equal`\n",
      "     |  \n",
      "     |  erf(...)\n",
      "     |      erf() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erf`\n",
      "     |  \n",
      "     |  erf_(...)\n",
      "     |      erf_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erf`\n",
      "     |  \n",
      "     |  erfc(...)\n",
      "     |      erfc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfc`\n",
      "     |  \n",
      "     |  erfc_(...)\n",
      "     |      erfc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfc`\n",
      "     |  \n",
      "     |  erfinv(...)\n",
      "     |      erfinv() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.erfinv`\n",
      "     |  \n",
      "     |  erfinv_(...)\n",
      "     |      erfinv_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.erfinv`\n",
      "     |  \n",
      "     |  exp(...)\n",
      "     |      exp() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.exp`\n",
      "     |  \n",
      "     |  exp_(...)\n",
      "     |      exp_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.exp`\n",
      "     |  \n",
      "     |  expand(...)\n",
      "     |      expand(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new view of the :attr:`self` tensor with singleton dimensions expanded\n",
      "     |      to a larger size.\n",
      "     |      \n",
      "     |      Passing -1 as the size for a dimension means not changing the size of\n",
      "     |      that dimension.\n",
      "     |      \n",
      "     |      Tensor can be also expanded to a larger number of dimensions, and the\n",
      "     |      new ones will be appended at the front. For the new dimensions, the\n",
      "     |      size cannot be set to -1.\n",
      "     |      \n",
      "     |      Expanding a tensor does not allocate new memory, but only creates a\n",
      "     |      new view on the existing tensor where a dimension of size one is\n",
      "     |      expanded to a larger size by setting the ``stride`` to 0. Any dimension\n",
      "     |      of size 1 can be expanded to an arbitrary value without allocating new\n",
      "     |      memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *sizes (torch.Size or int...): the desired expanded size\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          More than one element of an expanded tensor may refer to a single\n",
      "     |          memory location. As a result, in-place operations (especially ones that\n",
      "     |          are vectorized) may result in incorrect behavior. If you need to write\n",
      "     |          to the tensors, please clone them first.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1], [2], [3]])\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([3, 1])\n",
      "     |          >>> x.expand(3, 4)\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |          >>> x.expand(-1, 4)   # -1 means not changing the size of that dimension\n",
      "     |          tensor([[ 1,  1,  1,  1],\n",
      "     |                  [ 2,  2,  2,  2],\n",
      "     |                  [ 3,  3,  3,  3]])\n",
      "     |  \n",
      "     |  expand_as(...)\n",
      "     |      expand_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Expand this tensor to the same size as :attr:`other`.\n",
      "     |      ``self.expand_as(other)`` is equivalent to ``self.expand(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.expand` for more information about ``expand``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  expm1(...)\n",
      "     |      expm1() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.expm1`\n",
      "     |  \n",
      "     |  expm1_(...)\n",
      "     |      expm1_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.expm1`\n",
      "     |  \n",
      "     |  exponential_(...)\n",
      "     |      exponential_(lambd=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the exponential distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\lambda e^{-\\lambda x}\n",
      "     |  \n",
      "     |  fft(...)\n",
      "     |      fft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fft`\n",
      "     |  \n",
      "     |  fill_(...)\n",
      "     |      fill_(value) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with the specified value.\n",
      "     |  \n",
      "     |  flatten(...)\n",
      "     |      flatten(input, start_dim=0, end_dim=-1) -> Tensor\n",
      "     |      \n",
      "     |      see :func:`torch.flatten`\n",
      "     |  \n",
      "     |  flip(...)\n",
      "     |      flip(dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.flip`\n",
      "     |  \n",
      "     |  float(...)\n",
      "     |      float() -> Tensor\n",
      "     |      \n",
      "     |      ``self.float()`` is equivalent to ``self.to(torch.float32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  floor(...)\n",
      "     |      floor() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.floor`\n",
      "     |  \n",
      "     |  floor_(...)\n",
      "     |      floor_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.floor`\n",
      "     |  \n",
      "     |  fmod(...)\n",
      "     |      fmod(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.fmod`\n",
      "     |  \n",
      "     |  fmod_(...)\n",
      "     |      fmod_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.fmod`\n",
      "     |  \n",
      "     |  frac(...)\n",
      "     |      frac() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.frac`\n",
      "     |  \n",
      "     |  frac_(...)\n",
      "     |      frac_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.frac`\n",
      "     |  \n",
      "     |  gather(...)\n",
      "     |      gather(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gather`\n",
      "     |  \n",
      "     |  ge(...)\n",
      "     |      ge(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ge`\n",
      "     |  \n",
      "     |  ge_(...)\n",
      "     |      ge_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ge`\n",
      "     |  \n",
      "     |  gels(...)\n",
      "     |      gels(A) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gels`\n",
      "     |  \n",
      "     |  geometric_(...)\n",
      "     |      geometric_(p, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements drawn from the geometric distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(X=k) = (1 - p)^{k - 1} p\n",
      "     |  \n",
      "     |  geqrf(...)\n",
      "     |      geqrf() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.geqrf`\n",
      "     |  \n",
      "     |  ger(...)\n",
      "     |      ger(vec2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ger`\n",
      "     |  \n",
      "     |  get_device(...)\n",
      "     |      get_device() -> Device ordinal (Integer)\n",
      "     |      \n",
      "     |      For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.\n",
      "     |      For CPU tensors, an error is thrown.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(3, 4, 5, device='cuda:0')\n",
      "     |          >>> x.get_device()\n",
      "     |          0\n",
      "     |          >>> x.cpu().get_device()  # RuntimeError: get_device is not implemented for type torch.FloatTensor\n",
      "     |  \n",
      "     |  gt(...)\n",
      "     |      gt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.gt`\n",
      "     |  \n",
      "     |  gt_(...)\n",
      "     |      gt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.gt`\n",
      "     |  \n",
      "     |  half(...)\n",
      "     |      half() -> Tensor\n",
      "     |      \n",
      "     |      ``self.half()`` is equivalent to ``self.to(torch.float16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  hardshrink(...)\n",
      "     |      hardshrink(lambd=0.5) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.nn.functional.hardshrink`\n",
      "     |  \n",
      "     |  histc(...)\n",
      "     |      histc(bins=100, min=0, max=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.histc`\n",
      "     |  \n",
      "     |  ifft(...)\n",
      "     |      ifft(signal_ndim, normalized=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ifft`\n",
      "     |  \n",
      "     |  index_add(...)\n",
      "     |      index_add(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_add_`\n",
      "     |  \n",
      "     |  index_add_(...)\n",
      "     |      index_add_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Accumulate the elements of :attr:`tensor` into the :attr:`self` tensor by adding\n",
      "     |      to the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is added to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.ones(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_add_(0, index, t)\n",
      "     |          tensor([[  2.,   3.,   4.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  8.,   9.,  10.],\n",
      "     |                  [  1.,   1.,   1.],\n",
      "     |                  [  5.,   6.,   7.]])\n",
      "     |  \n",
      "     |  index_copy(...)\n",
      "     |      index_copy(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_copy_`\n",
      "     |  \n",
      "     |  index_copy_(...)\n",
      "     |      index_copy_(dim, index, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements of :attr:`tensor` into the :attr:`self` tensor by selecting\n",
      "     |      the indices in the order given in :attr:`index`. For example, if ``dim == 0``\n",
      "     |      and ``index[i] == j``, then the ``i``\\ th row of :attr:`tensor` is copied to the\n",
      "     |      ``j``\\ th row of :attr:`self`.\n",
      "     |      \n",
      "     |      The :attr:`dim`\\ th dimension of :attr:`tensor` must have the same size as the\n",
      "     |      length of :attr:`index` (which must be a vector), and all other dimensions must\n",
      "     |      match :attr:`self`, or an error will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`tensor` to select from\n",
      "     |          tensor (Tensor): the tensor containing values to copy\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.zeros(5, 3)\n",
      "     |          >>> t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 4, 2])\n",
      "     |          >>> x.index_copy_(0, index, t)\n",
      "     |          tensor([[ 1.,  2.,  3.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 7.,  8.,  9.],\n",
      "     |                  [ 0.,  0.,  0.],\n",
      "     |                  [ 4.,  5.,  6.]])\n",
      "     |  \n",
      "     |  index_fill(...)\n",
      "     |      index_fill(dim, index, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.index_fill_`\n",
      "     |  \n",
      "     |  index_fill_(...)\n",
      "     |      index_fill_(dim, index, val) -> Tensor\n",
      "     |      \n",
      "     |      Fills the elements of the :attr:`self` tensor with value :attr:`val` by\n",
      "     |      selecting the indices in the order given in :attr:`index`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): dimension along which to index\n",
      "     |          index (LongTensor): indices of :attr:`self` tensor to fill in\n",
      "     |          val (float): the value to fill with\n",
      "     |      \n",
      "     |      Example::\n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
      "     |          >>> index = torch.tensor([0, 2])\n",
      "     |          >>> x.index_fill_(1, index, -1)\n",
      "     |          tensor([[-1.,  2., -1.],\n",
      "     |                  [-1.,  5., -1.],\n",
      "     |                  [-1.,  8., -1.]])\n",
      "     |  \n",
      "     |  index_put(...)\n",
      "     |      index_put(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Out-place version of :meth:`~Tensor.index_put_`\n",
      "     |  \n",
      "     |  index_put_(...)\n",
      "     |      index_put_(indices, value, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Puts values from the tensor :attr:`value` into the tensor :attr:`self` using\n",
      "     |      the indices specified in :attr:`indices` (which is a tuple of Tensors). The\n",
      "     |      expression ``tensor.index_put_(indices, value)`` is equivalent to\n",
      "     |      ``tensor[indices] = value``. Returns :attr:`self`.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (tuple of LongTensor): tensors used to index into `self`.\n",
      "     |          value (Tensor): tensor of same dtype as `self`.\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |  \n",
      "     |  index_select(...)\n",
      "     |      index_select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.index_select`\n",
      "     |  \n",
      "     |  indices(...)\n",
      "     |      indices() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained indices tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.values`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  int(...)\n",
      "     |      int() -> Tensor\n",
      "     |      \n",
      "     |      ``self.int()`` is equivalent to ``self.to(torch.int32)``. See :func:`to`.\n",
      "     |  \n",
      "     |  int_repr(...)\n",
      "     |      int_repr() -> Tensor\n",
      "     |      \n",
      "     |      Given a quantized Tensor,\n",
      "     |      ``self.int_repr()`` returns a CPU Tensor with uint8_t as data type that stores the\n",
      "     |      underlying uint8_t values of the given Tensor.\n",
      "     |  \n",
      "     |  inverse(...)\n",
      "     |      inverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.inverse`\n",
      "     |  \n",
      "     |  irfft(...)\n",
      "     |      irfft(signal_ndim, normalized=False, onesided=True, signal_sizes=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.irfft`\n",
      "     |  \n",
      "     |  is_coalesced(...)\n",
      "     |  \n",
      "     |  is_complex(...)\n",
      "     |  \n",
      "     |  is_contiguous(...)\n",
      "     |      is_contiguous() -> bool\n",
      "     |      \n",
      "     |      Returns True if :attr:`self` tensor is contiguous in memory in C order.\n",
      "     |  \n",
      "     |  is_distributed(...)\n",
      "     |  \n",
      "     |  is_floating_point(...)\n",
      "     |      is_floating_point() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a floating point data type.\n",
      "     |  \n",
      "     |  is_nonzero(...)\n",
      "     |  \n",
      "     |  is_same_size(...)\n",
      "     |  \n",
      "     |  is_set_to(...)\n",
      "     |      is_set_to(tensor) -> bool\n",
      "     |      \n",
      "     |      Returns True if this object refers to the same ``THTensor`` object from the\n",
      "     |      Torch C API as the given tensor.\n",
      "     |  \n",
      "     |  is_signed(...)\n",
      "     |      is_signed() -> bool\n",
      "     |      \n",
      "     |      Returns True if the data type of :attr:`self` is a signed data type.\n",
      "     |  \n",
      "     |  isclose(...)\n",
      "     |  \n",
      "     |  item(...)\n",
      "     |      item() -> number\n",
      "     |      \n",
      "     |      Returns the value of this tensor as a standard Python number. This only works\n",
      "     |      for tensors with one element. For other cases, see :meth:`~Tensor.tolist`.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1.0])\n",
      "     |          >>> x.item()\n",
      "     |          1.0\n",
      "     |  \n",
      "     |  kthvalue(...)\n",
      "     |      kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.kthvalue`\n",
      "     |  \n",
      "     |  le(...)\n",
      "     |      le(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.le`\n",
      "     |  \n",
      "     |  le_(...)\n",
      "     |      le_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.le`\n",
      "     |  \n",
      "     |  lerp(...)\n",
      "     |      lerp(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lerp`\n",
      "     |  \n",
      "     |  lerp_(...)\n",
      "     |      lerp_(end, weight) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lerp`\n",
      "     |  \n",
      "     |  lgamma(...)\n",
      "     |  \n",
      "     |  lgamma_(...)\n",
      "     |  \n",
      "     |  log(...)\n",
      "     |      log() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log`\n",
      "     |  \n",
      "     |  log10(...)\n",
      "     |      log10() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log10`\n",
      "     |  \n",
      "     |  log10_(...)\n",
      "     |      log10_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log10`\n",
      "     |  \n",
      "     |  log1p(...)\n",
      "     |      log1p() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log1p`\n",
      "     |  \n",
      "     |  log1p_(...)\n",
      "     |      log1p_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log1p`\n",
      "     |  \n",
      "     |  log2(...)\n",
      "     |      log2() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.log2`\n",
      "     |  \n",
      "     |  log2_(...)\n",
      "     |      log2_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log2`\n",
      "     |  \n",
      "     |  log_(...)\n",
      "     |      log_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.log`\n",
      "     |  \n",
      "     |  log_normal_(...)\n",
      "     |      log_normal_(mean=1, std=2, *, generator=None)\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers samples from the log-normal distribution\n",
      "     |      parameterized by the given mean :math:`\\mu` and standard deviation\n",
      "     |      :math:`\\sigma`. Note that :attr:`mean` and :attr:`std` are the mean and\n",
      "     |      standard deviation of the underlying normal distribution, and not of the\n",
      "     |      returned distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |          f(x) = \\dfrac{1}{x \\sigma \\sqrt{2\\pi}}\\ e^{-\\frac{(\\ln x - \\mu)^2}{2\\sigma^2}}\n",
      "     |  \n",
      "     |  log_softmax(...)\n",
      "     |  \n",
      "     |  logdet(...)\n",
      "     |      logdet() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logdet`\n",
      "     |  \n",
      "     |  logsumexp(...)\n",
      "     |      logsumexp(dim, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.logsumexp`\n",
      "     |  \n",
      "     |  long(...)\n",
      "     |      long() -> Tensor\n",
      "     |      \n",
      "     |      ``self.long()`` is equivalent to ``self.to(torch.int64)``. See :func:`to`.\n",
      "     |  \n",
      "     |  lt(...)\n",
      "     |      lt(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lt`\n",
      "     |  \n",
      "     |  lt_(...)\n",
      "     |      lt_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.lt`\n",
      "     |  \n",
      "     |  lu_solve(...)\n",
      "     |      lu_solve(LU_data, LU_pivots) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.lu_solve`\n",
      "     |  \n",
      "     |  map2_(...)\n",
      "     |  \n",
      "     |  map_(...)\n",
      "     |      map_(tensor, callable)\n",
      "     |      \n",
      "     |      Applies :attr:`callable` for each element in :attr:`self` tensor and the given\n",
      "     |      :attr:`tensor` and stores the results in :attr:`self` tensor. :attr:`self` tensor and\n",
      "     |      the given :attr:`tensor` must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "     |      \n",
      "     |      The :attr:`callable` should have the signature::\n",
      "     |      \n",
      "     |          def callable(a, b) -> number\n",
      "     |  \n",
      "     |  masked_fill(...)\n",
      "     |      masked_fill(mask, value) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_fill_`\n",
      "     |  \n",
      "     |  masked_fill_(...)\n",
      "     |      masked_fill_(mask, value)\n",
      "     |      \n",
      "     |      Fills elements of :attr:`self` tensor with :attr:`value` where :attr:`mask` is\n",
      "     |      one. The shape of :attr:`mask` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          value (float): the value to fill in with\n",
      "     |  \n",
      "     |  masked_scatter(...)\n",
      "     |      masked_scatter(mask, tensor) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.masked_scatter_`\n",
      "     |  \n",
      "     |  masked_scatter_(...)\n",
      "     |      masked_scatter_(mask, source)\n",
      "     |      \n",
      "     |      Copies elements from :attr:`source` into :attr:`self` tensor at positions where\n",
      "     |      the :attr:`mask` is one.\n",
      "     |      The shape of :attr:`mask` must be :ref:`broadcastable <broadcasting-semantics>`\n",
      "     |      with the shape of the underlying tensor. The :attr:`source` should have at least\n",
      "     |      as many elements as the number of ones in :attr:`mask`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          mask (ByteTensor): the binary mask\n",
      "     |          source (Tensor): the tensor to copy from\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The :attr:`mask` operates on the :attr:`self` tensor, not on the given\n",
      "     |          :attr:`source` tensor.\n",
      "     |  \n",
      "     |  masked_select(...)\n",
      "     |      masked_select(mask) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.masked_select`\n",
      "     |  \n",
      "     |  matmul(...)\n",
      "     |      matmul(tensor2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matmul`\n",
      "     |  \n",
      "     |  matrix_power(...)\n",
      "     |      matrix_power(n) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.matrix_power`\n",
      "     |  \n",
      "     |  max(...)\n",
      "     |      max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.max`\n",
      "     |  \n",
      "     |  mean(...)\n",
      "     |      mean(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mean`\n",
      "     |  \n",
      "     |  median(...)\n",
      "     |      median(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.median`\n",
      "     |  \n",
      "     |  min(...)\n",
      "     |      min(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.min`\n",
      "     |  \n",
      "     |  mm(...)\n",
      "     |      mm(mat2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mm`\n",
      "     |  \n",
      "     |  mode(...)\n",
      "     |      mode(dim=None, keepdim=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.mode`\n",
      "     |  \n",
      "     |  mul(...)\n",
      "     |      mul(value) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mul`\n",
      "     |  \n",
      "     |  mul_(...)\n",
      "     |      mul_(value)\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mul`\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(num_samples, replacement=False, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.multinomial`\n",
      "     |  \n",
      "     |  mv(...)\n",
      "     |      mv(vec) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mv`\n",
      "     |  \n",
      "     |  mvlgamma(...)\n",
      "     |      mvlgamma(p) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.mvlgamma`\n",
      "     |  \n",
      "     |  mvlgamma_(...)\n",
      "     |      mvlgamma_(p) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.mvlgamma`\n",
      "     |  \n",
      "     |  narrow(...)\n",
      "     |      narrow(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.narrow`\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      "     |          >>> x.narrow(0, 0, 2)\n",
      "     |          tensor([[ 1,  2,  3],\n",
      "     |                  [ 4,  5,  6]])\n",
      "     |          >>> x.narrow(1, 1, 2)\n",
      "     |          tensor([[ 2,  3],\n",
      "     |                  [ 5,  6],\n",
      "     |                  [ 8,  9]])\n",
      "     |  \n",
      "     |  narrow_copy(...)\n",
      "     |      narrow_copy(dimension, start, length) -> Tensor\n",
      "     |      \n",
      "     |      Same as :meth:`Tensor.narrow` except returning a copy rather\n",
      "     |      than shared storage.  This is primarily for sparse tensors, which\n",
      "     |      do not have a shared-storage narrow method.  Calling ```narrow_copy``\n",
      "     |      with ```dimemsion > self.sparse_dim()``` will return a copy with the\n",
      "     |      relevant dense dimension narrowed, and ```self.shape``` updated accordingly.\n",
      "     |  \n",
      "     |  ndimension(...)\n",
      "     |      ndimension() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.dim()`\n",
      "     |  \n",
      "     |  ne(...)\n",
      "     |      ne(other) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ne`\n",
      "     |  \n",
      "     |  ne_(...)\n",
      "     |      ne_(other) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.ne`\n",
      "     |  \n",
      "     |  neg(...)\n",
      "     |      neg() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.neg`\n",
      "     |  \n",
      "     |  neg_(...)\n",
      "     |      neg_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.neg`\n",
      "     |  \n",
      "     |  nelement(...)\n",
      "     |      nelement() -> int\n",
      "     |      \n",
      "     |      Alias for :meth:`~Tensor.numel`\n",
      "     |  \n",
      "     |  new(...)\n",
      "     |  \n",
      "     |  new_empty(...)\n",
      "     |      new_empty(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with uninitialized data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones(())\n",
      "     |          >>> tensor.new_empty((2, 3))\n",
      "     |          tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],\n",
      "     |                  [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])\n",
      "     |  \n",
      "     |  new_full(...)\n",
      "     |      new_full(size, fill_value, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with :attr:`fill_value`.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          fill_value (scalar): the number to fill the output tensor with.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.float64)\n",
      "     |          >>> tensor.new_full((3, 4), 3.141592)\n",
      "     |          tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416],\n",
      "     |                  [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  new_ones(...)\n",
      "     |      new_ones(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``1``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.int32)\n",
      "     |          >>> tensor.new_ones((2, 3))\n",
      "     |          tensor([[ 1,  1,  1],\n",
      "     |                  [ 1,  1,  1]], dtype=torch.int32)\n",
      "     |  \n",
      "     |  new_tensor(...)\n",
      "     |      new_tensor(data, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new Tensor with :attr:`data` as the tensor data.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`new_tensor` always copies :attr:`data`. If you have a Tensor\n",
      "     |          ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "     |          or :func:`torch.Tensor.detach`.\n",
      "     |          If you have a numpy array and want to avoid a copy, use\n",
      "     |          :func:`torch.from_numpy`.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          When data is a tensor `x`, :func:`new_tensor()` reads out 'the data' from whatever it is passed,\n",
      "     |          and constructs a leaf variable. Therefore ``tensor.new_tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "     |          and ``tensor.new_tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "     |          The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          data (array_like): The returned Tensor copies :attr:`data`.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.ones((2,), dtype=torch.int8)\n",
      "     |          >>> data = [[0, 1], [2, 3]]\n",
      "     |          >>> tensor.new_tensor(data)\n",
      "     |          tensor([[ 0,  1],\n",
      "     |                  [ 2,  3]], dtype=torch.int8)\n",
      "     |  \n",
      "     |  new_zeros(...)\n",
      "     |      new_zeros(size, dtype=None, device=None, requires_grad=False) -> Tensor\n",
      "     |      \n",
      "     |      Returns a Tensor of size :attr:`size` filled with ``0``.\n",
      "     |      By default, the returned Tensor has the same :class:`torch.dtype` and\n",
      "     |      :class:`torch.device` as this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n",
      "     |              shape of the output tensor.\n",
      "     |          dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.dtype` as this tensor.\n",
      "     |          device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "     |              Default: if None, same :class:`torch.device` as this tensor.\n",
      "     |          requires_grad (bool, optional): If autograd should record operations on the\n",
      "     |              returned tensor. Default: ``False``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.tensor((), dtype=torch.float64)\n",
      "     |          >>> tensor.new_zeros((2, 3))\n",
      "     |          tensor([[ 0.,  0.,  0.],\n",
      "     |                  [ 0.,  0.,  0.]], dtype=torch.float64)\n",
      "     |  \n",
      "     |  nonzero(...)\n",
      "     |      nonzero() -> LongTensor\n",
      "     |      \n",
      "     |      See :func:`torch.nonzero`\n",
      "     |  \n",
      "     |  normal_(...)\n",
      "     |      normal_(mean=0, std=1, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with elements samples from the normal distribution\n",
      "     |      parameterized by :attr:`mean` and :attr:`std`.\n",
      "     |  \n",
      "     |  numel(...)\n",
      "     |      numel() -> int\n",
      "     |      \n",
      "     |      See :func:`torch.numel`\n",
      "     |  \n",
      "     |  numpy(...)\n",
      "     |      numpy() -> numpy.ndarray\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor as a NumPy :class:`ndarray`. This tensor and the\n",
      "     |      returned :class:`ndarray` share the same underlying storage. Changes to\n",
      "     |      :attr:`self` tensor will be reflected in the :class:`ndarray` and vice versa.\n",
      "     |  \n",
      "     |  orgqr(...)\n",
      "     |      orgqr(input2) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.orgqr`\n",
      "     |  \n",
      "     |  ormqr(...)\n",
      "     |      ormqr(input2, input3, left=True, transpose=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.ormqr`\n",
      "     |  \n",
      "     |  permute(...)\n",
      "     |      permute(*dims) -> Tensor\n",
      "     |      \n",
      "     |      Permute the dimensions of this tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *dims (int...): The desired ordering of dimensions\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          >>> x = torch.randn(2, 3, 5)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([2, 3, 5])\n",
      "     |          >>> x.permute(2, 0, 1).size()\n",
      "     |          torch.Size([5, 2, 3])\n",
      "     |  \n",
      "     |  pin_memory(...)\n",
      "     |      pin_memory() -> Tensor\n",
      "     |      \n",
      "     |      Copies the tensor to pinned memory, if it's not already pinned.\n",
      "     |  \n",
      "     |  pinverse(...)\n",
      "     |      pinverse() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pinverse`\n",
      "     |  \n",
      "     |  polygamma(...)\n",
      "     |  \n",
      "     |  polygamma_(...)\n",
      "     |  \n",
      "     |  pow(...)\n",
      "     |      pow(exponent) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.pow`\n",
      "     |  \n",
      "     |  pow_(...)\n",
      "     |      pow_(exponent) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.pow`\n",
      "     |  \n",
      "     |  prelu(...)\n",
      "     |  \n",
      "     |  prod(...)\n",
      "     |      prod(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.prod`\n",
      "     |  \n",
      "     |  put_(...)\n",
      "     |      put_(indices, tensor, accumulate=False) -> Tensor\n",
      "     |      \n",
      "     |      Copies the elements from :attr:`tensor` into the positions specified by\n",
      "     |      indices. For the purpose of indexing, the :attr:`self` tensor is treated as if\n",
      "     |      it were a 1-D tensor.\n",
      "     |      \n",
      "     |      If :attr:`accumulate` is ``True``, the elements in :attr:`tensor` are added to\n",
      "     |      :attr:`self`. If accumulate is ``False``, the behavior is undefined if indices\n",
      "     |      contain duplicate elements.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          indices (LongTensor): the indices into self\n",
      "     |          tensor (Tensor): the tensor containing values to copy from\n",
      "     |          accumulate (bool): whether to accumulate into self\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> src = torch.tensor([[4, 3, 5],\n",
      "     |                                  [6, 7, 8]])\n",
      "     |          >>> src.put_(torch.tensor([1, 3]), torch.tensor([9, 10]))\n",
      "     |          tensor([[  4,   9,   5],\n",
      "     |                  [ 10,   7,   8]])\n",
      "     |  \n",
      "     |  q_scale(...)\n",
      "     |      q_scale() -> float\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the scale of the underlying quantizer().\n",
      "     |  \n",
      "     |  q_zero_point(...)\n",
      "     |      q_zero_point() -> int\n",
      "     |      \n",
      "     |      Given a Tensor quantized by linear(affine) quantization,\n",
      "     |      returns the zero_point of the underlying quantizer().\n",
      "     |  \n",
      "     |  qr(...)\n",
      "     |      qr() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.qr`\n",
      "     |  \n",
      "     |  quantize_linear(...)\n",
      "     |      quantize_linear(scale, zero_point) -> Tensor\n",
      "     |      \n",
      "     |      Quantize a float Tensor using affine quantization scheme with given scale and\n",
      "     |      zero_point.\n",
      "     |      returns the quantized Tensor.\n",
      "     |  \n",
      "     |  random_(...)\n",
      "     |      random_(from=0, to=None, *, generator=None) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the discrete uniform\n",
      "     |      distribution over ``[from, to - 1]``. If not specified, the values are usually\n",
      "     |      only bounded by :attr:`self` tensor's data type. However, for floating point\n",
      "     |      types, if unspecified, range will be ``[0, 2^mantissa]`` to ensure that every\n",
      "     |      value is representable. For example, `torch.tensor(1, dtype=torch.double).random_()`\n",
      "     |      will be uniform in ``[0, 2^53]``.\n",
      "     |  \n",
      "     |  reciprocal(...)\n",
      "     |      reciprocal() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.reciprocal`\n",
      "     |  \n",
      "     |  reciprocal_(...)\n",
      "     |      reciprocal_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.reciprocal`\n",
      "     |  \n",
      "     |  record_stream(...)\n",
      "     |  \n",
      "     |  relu(...)\n",
      "     |  \n",
      "     |  relu_(...)\n",
      "     |  \n",
      "     |  remainder(...)\n",
      "     |      remainder(divisor) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.remainder`\n",
      "     |  \n",
      "     |  remainder_(...)\n",
      "     |      remainder_(divisor) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.remainder`\n",
      "     |  \n",
      "     |  renorm(...)\n",
      "     |      renorm(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.renorm`\n",
      "     |  \n",
      "     |  renorm_(...)\n",
      "     |      renorm_(p, dim, maxnorm) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.renorm`\n",
      "     |  \n",
      "     |  repeat(...)\n",
      "     |      repeat(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Repeats this tensor along the specified dimensions.\n",
      "     |      \n",
      "     |      Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          :func:`torch.repeat` behaves differently from\n",
      "     |          `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "     |          but is more similar to\n",
      "     |          `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "     |          For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "     |              dimension\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3])\n",
      "     |          >>> x.repeat(4, 2)\n",
      "     |          tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3],\n",
      "     |                  [ 1,  2,  3,  1,  2,  3]])\n",
      "     |          >>> x.repeat(4, 2, 1).size()\n",
      "     |          torch.Size([4, 2, 3])\n",
      "     |  \n",
      "     |  repeat_interleave(...)\n",
      "     |      repeat_interleave(repeats, dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.repeat_interleave`.\n",
      "     |  \n",
      "     |  requires_grad_(...)\n",
      "     |      requires_grad_(requires_grad=True) -> Tensor\n",
      "     |      \n",
      "     |      Change if autograd should record operations on this tensor: sets this tensor's\n",
      "     |      :attr:`requires_grad` attribute in-place. Returns this tensor.\n",
      "     |      \n",
      "     |      :func:`require_grad_`'s main use case is to tell autograd to begin recording\n",
      "     |      operations on a Tensor ``tensor``. If ``tensor`` has ``requires_grad=False``\n",
      "     |      (because it was obtained through a DataLoader, or required preprocessing or\n",
      "     |      initialization), ``tensor.requires_grad_()`` makes it so that autograd will\n",
      "     |      begin to record operations on ``tensor``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          requires_grad (bool): If autograd should record operations on this tensor.\n",
      "     |              Default: ``True``.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> # Let's say we want to preprocess some saved weights and use\n",
      "     |          >>> # the result as new weights.\n",
      "     |          >>> saved_weights = [0.1, 0.2, 0.3, 0.25]\n",
      "     |          >>> loaded_weights = torch.tensor(saved_weights)\n",
      "     |          >>> weights = preprocess(loaded_weights)  # some function\n",
      "     |          >>> weights\n",
      "     |          tensor([-0.5503,  0.4926, -2.1158, -0.8303])\n",
      "     |      \n",
      "     |          >>> # Now, start to record operations done to weights\n",
      "     |          >>> weights.requires_grad_()\n",
      "     |          >>> out = weights.pow(2).sum()\n",
      "     |          >>> out.backward()\n",
      "     |          >>> weights.grad\n",
      "     |          tensor([-1.1007,  0.9853, -4.2316, -1.6606])\n",
      "     |  \n",
      "     |  reshape(...)\n",
      "     |      reshape(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor with the same data and number of elements as :attr:`self`\n",
      "     |      but with the specified shape. This method returns a view if :attr:`shape` is\n",
      "     |      compatible with the current shape. See :meth:`torch.Tensor.view` on when it is\n",
      "     |      possible to return a view.\n",
      "     |      \n",
      "     |      See :func:`torch.reshape`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (tuple of ints or int...): the desired shape\n",
      "     |  \n",
      "     |  reshape_as(...)\n",
      "     |      reshape_as(other) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor as the same shape as :attr:`other`.\n",
      "     |      ``self.reshape_as(other)`` is equivalent to ``self.reshape(other.sizes())``.\n",
      "     |      This method returns a view if ``other.sizes()`` is compatible with the current\n",
      "     |      shape. See :meth:`torch.Tensor.view` on when it is possible to return a view.\n",
      "     |      \n",
      "     |      Please see :meth:`reshape` for more information about ``reshape``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same shape\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  resize_(...)\n",
      "     |      resize_(*sizes) -> Tensor\n",
      "     |      \n",
      "     |      Resizes :attr:`self` tensor to the specified size. If the number of elements is\n",
      "     |      larger than the current storage size, then the underlying storage is resized\n",
      "     |      to fit the new number of elements. If the number of elements is smaller, the\n",
      "     |      underlying storage is not changed. Existing elements are preserved but any new\n",
      "     |      memory is uninitialized.\n",
      "     |      \n",
      "     |      .. warning::\n",
      "     |      \n",
      "     |          This is a low-level method. The storage is reinterpreted as C-contiguous,\n",
      "     |          ignoring the current strides (unless the target size equals the current\n",
      "     |          size, in which case the tensor is left unchanged). For most purposes, you\n",
      "     |          will instead want to use :meth:`~Tensor.view()`, which checks for\n",
      "     |          contiguity, or :meth:`~Tensor.reshape()`, which copies data if needed. To\n",
      "     |          change the size in-place with custom strides, see :meth:`~Tensor.set_()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sizes (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
      "     |          >>> x.resize_(2, 2)\n",
      "     |          tensor([[ 1,  2],\n",
      "     |                  [ 3,  4]])\n",
      "     |  \n",
      "     |  resize_as_(...)\n",
      "     |      resize_as_(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Resizes the :attr:`self` tensor to be the same size as the specified\n",
      "     |      :attr:`tensor`. This is equivalent to ``self.resize_(tensor.size())``.\n",
      "     |  \n",
      "     |  rfft(...)\n",
      "     |      rfft(signal_ndim, normalized=False, onesided=True) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rfft`\n",
      "     |  \n",
      "     |  roll(...)\n",
      "     |      roll(shifts, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.roll`\n",
      "     |  \n",
      "     |  rot90(...)\n",
      "     |      rot90(k, dims) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rot90`\n",
      "     |  \n",
      "     |  round(...)\n",
      "     |      round() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.round`\n",
      "     |  \n",
      "     |  round_(...)\n",
      "     |      round_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.round`\n",
      "     |  \n",
      "     |  rsqrt(...)\n",
      "     |      rsqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.rsqrt`\n",
      "     |  \n",
      "     |  rsqrt_(...)\n",
      "     |      rsqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.rsqrt`\n",
      "     |  \n",
      "     |  scatter(...)\n",
      "     |      scatter(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_`\n",
      "     |  \n",
      "     |  scatter_(...)\n",
      "     |      scatter_(dim, index, src) -> Tensor\n",
      "     |      \n",
      "     |      Writes all values from the tensor :attr:`src` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor. For each value in :attr:`src`, its output\n",
      "     |      index is specified by its index in :attr:`src` for ``dimension != dim`` and by\n",
      "     |      the corresponding value in :attr:`index` for ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      This is the reverse operation of the manner described in :meth:`~Tensor.gather`.\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`src` (if it is a Tensor) should have same\n",
      "     |      number of dimensions. It is also required that ``index.size(d) <= src.size(d)``\n",
      "     |      for all dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all\n",
      "     |      dimensions ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row\n",
      "     |      along the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity\n",
      "     |          src (Tensor): the source element(s) to scatter,\n",
      "     |            incase `value` is not specified\n",
      "     |          value (float): the source element(s) to scatter,\n",
      "     |            incase `src` is not specified\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[ 0.3992,  0.2908,  0.9044,  0.4850,  0.6004],\n",
      "     |                  [ 0.5735,  0.9006,  0.6797,  0.4152,  0.1732]])\n",
      "     |          >>> torch.zeros(3, 5).scatter_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[ 0.3992,  0.9006,  0.6797,  0.4850,  0.6004],\n",
      "     |                  [ 0.0000,  0.2908,  0.0000,  0.4152,  0.0000],\n",
      "     |                  [ 0.5735,  0.0000,  0.9044,  0.0000,  0.1732]])\n",
      "     |      \n",
      "     |          >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
      "     |          >>> z\n",
      "     |          tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
      "     |                  [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
      "     |  \n",
      "     |  scatter_add(...)\n",
      "     |      scatter_add(dim, index, source) -> Tensor\n",
      "     |      \n",
      "     |      Out-of-place version of :meth:`torch.Tensor.scatter_add_`\n",
      "     |  \n",
      "     |  scatter_add_(...)\n",
      "     |      scatter_add_(dim, index, other) -> Tensor\n",
      "     |      \n",
      "     |      Adds all values from the tensor :attr:`other` into :attr:`self` at the indices\n",
      "     |      specified in the :attr:`index` tensor in a similar fashion as\n",
      "     |      :meth:`~torch.Tensor.scatter_`. For each value in :attr:`other`, it is added to\n",
      "     |      an index in :attr:`self` which is specified by its index in :attr:`other`\n",
      "     |      for ``dimension != dim`` and by the corresponding value in :attr:`index` for\n",
      "     |      ``dimension = dim``.\n",
      "     |      \n",
      "     |      For a 3-D tensor, :attr:`self` is updated as::\n",
      "     |      \n",
      "     |          self[index[i][j][k]][j][k] += other[i][j][k]  # if dim == 0\n",
      "     |          self[i][index[i][j][k]][k] += other[i][j][k]  # if dim == 1\n",
      "     |          self[i][j][index[i][j][k]] += other[i][j][k]  # if dim == 2\n",
      "     |      \n",
      "     |      :attr:`self`, :attr:`index` and :attr:`other` should have same number of\n",
      "     |      dimensions. It is also required that ``index.size(d) <= other.size(d)`` for all\n",
      "     |      dimensions ``d``, and that ``index.size(d) <= self.size(d)`` for all dimensions\n",
      "     |      ``d != dim``.\n",
      "     |      \n",
      "     |      Moreover, as for :meth:`~Tensor.gather`, the values of :attr:`index` must be\n",
      "     |      between ``0`` and ``self.size(dim) - 1`` inclusive, and all values in a row along\n",
      "     |      the specified dimension :attr:`dim` must be unique.\n",
      "     |      \n",
      "     |      .. include:: cuda_deterministic.rst\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the axis along which to index\n",
      "     |          index (LongTensor): the indices of elements to scatter and add,\n",
      "     |            can be either empty or the same size of src.\n",
      "     |            When empty, the operation returns identity.\n",
      "     |          other (Tensor): the source elements to scatter and add\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.rand(2, 5)\n",
      "     |          >>> x\n",
      "     |          tensor([[0.7404, 0.0427, 0.6480, 0.3806, 0.8328],\n",
      "     |                  [0.7953, 0.2009, 0.9154, 0.6782, 0.9620]])\n",
      "     |          >>> torch.ones(3, 5).scatter_add_(0, torch.tensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x)\n",
      "     |          tensor([[1.7404, 1.2009, 1.9154, 1.3806, 1.8328],\n",
      "     |                  [1.0000, 1.0427, 1.0000, 1.6782, 1.0000],\n",
      "     |                  [1.7953, 1.0000, 1.6480, 1.0000, 1.9620]])\n",
      "     |  \n",
      "     |  select(...)\n",
      "     |      select(dim, index) -> Tensor\n",
      "     |      \n",
      "     |      Slices the :attr:`self` tensor along the selected dimension at the given index.\n",
      "     |      This function returns a tensor with the given dimension removed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int): the dimension to slice\n",
      "     |          index (int): the index to select with\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          :meth:`select` is equivalent to slicing. For example,\n",
      "     |          ``tensor.select(0, index)`` is equivalent to ``tensor[index]`` and\n",
      "     |          ``tensor.select(2, index)`` is equivalent to ``tensor[:,:,index]``.\n",
      "     |  \n",
      "     |  set_(...)\n",
      "     |      set_(source=None, storage_offset=0, size=None, stride=None) -> Tensor\n",
      "     |      \n",
      "     |      Sets the underlying storage, size, and strides. If :attr:`source` is a tensor,\n",
      "     |      :attr:`self` tensor will share the same storage and have the same size and\n",
      "     |      strides as :attr:`source`. Changes to elements in one tensor will be reflected\n",
      "     |      in the other.\n",
      "     |      \n",
      "     |      If :attr:`source` is a :class:`~torch.Storage`, the method sets the underlying\n",
      "     |      storage, offset, size, and stride.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          source (Tensor or Storage): the tensor or storage to use\n",
      "     |          storage_offset (int, optional): the offset in the storage\n",
      "     |          size (torch.Size, optional): the desired size. Defaults to the size of the source.\n",
      "     |          stride (tuple, optional): the desired stride. Defaults to C-contiguous strides.\n",
      "     |  \n",
      "     |  short(...)\n",
      "     |      short() -> Tensor\n",
      "     |      \n",
      "     |      ``self.short()`` is equivalent to ``self.to(torch.int16)``. See :func:`to`.\n",
      "     |  \n",
      "     |  sigmoid(...)\n",
      "     |      sigmoid() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sigmoid`\n",
      "     |  \n",
      "     |  sigmoid_(...)\n",
      "     |      sigmoid_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sigmoid`\n",
      "     |  \n",
      "     |  sign(...)\n",
      "     |      sign() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sign`\n",
      "     |  \n",
      "     |  sign_(...)\n",
      "     |      sign_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sign`\n",
      "     |  \n",
      "     |  sin(...)\n",
      "     |      sin() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sin`\n",
      "     |  \n",
      "     |  sin_(...)\n",
      "     |      sin_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sin`\n",
      "     |  \n",
      "     |  sinh(...)\n",
      "     |      sinh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sinh`\n",
      "     |  \n",
      "     |  sinh_(...)\n",
      "     |      sinh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sinh`\n",
      "     |  \n",
      "     |  size(...)\n",
      "     |      size() -> torch.Size\n",
      "     |      \n",
      "     |      Returns the size of the :attr:`self` tensor. The returned value is a subclass of\n",
      "     |      :class:`tuple`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> torch.empty(3, 4, 5).size()\n",
      "     |          torch.Size([3, 4, 5])\n",
      "     |  \n",
      "     |  slogdet(...)\n",
      "     |      slogdet() -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.slogdet`\n",
      "     |  \n",
      "     |  smm(...)\n",
      "     |  \n",
      "     |  softmax(...)\n",
      "     |  \n",
      "     |  solve(...)\n",
      "     |      solve(A) -> Tensor, Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.solve`\n",
      "     |  \n",
      "     |  sort(...)\n",
      "     |      sort(dim=-1, descending=False) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.sort`\n",
      "     |  \n",
      "     |  sparse_dim(...)\n",
      "     |      sparse_dim() -> int\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a the number of sparse dimensions. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.dense_dim`.\n",
      "     |  \n",
      "     |  sparse_mask(...)\n",
      "     |      sparse_mask(input, mask) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new SparseTensor with values from Tensor :attr:`input` filtered\n",
      "     |      by indices of :attr:`mask` and values are ignored. :attr:`input` and :attr:`mask`\n",
      "     |      must have the same shape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          input (Tensor): an input Tensor\n",
      "     |          mask (SparseTensor): a SparseTensor which we filter :attr:`input` based on its indices\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> nnz = 5\n",
      "     |          >>> dims = [5, 5, 2, 2]\n",
      "     |          >>> I = torch.cat([torch.randint(0, dims[0], size=(nnz,)),\n",
      "     |                             torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)\n",
      "     |          >>> V = torch.randn(nnz, dims[2], dims[3])\n",
      "     |          >>> size = torch.Size(dims)\n",
      "     |          >>> S = torch.sparse_coo_tensor(I, V, size).coalesce()\n",
      "     |          >>> D = torch.randn(dims)\n",
      "     |          >>> D.sparse_mask(S)\n",
      "     |          tensor(indices=tensor([[0, 0, 0, 2],\n",
      "     |                                 [0, 1, 4, 3]]),\n",
      "     |                 values=tensor([[[ 1.6550,  0.2397],\n",
      "     |                                 [-0.1611, -0.0779]],\n",
      "     |      \n",
      "     |                                [[ 0.2326, -1.0558],\n",
      "     |                                 [ 1.4711,  1.9678]],\n",
      "     |      \n",
      "     |                                [[-0.5138, -0.0411],\n",
      "     |                                 [ 1.9417,  0.5158]],\n",
      "     |      \n",
      "     |                                [[ 0.0793,  0.0036],\n",
      "     |                                 [-0.2569, -0.1055]]]),\n",
      "     |                 size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  sparse_resize_(...)\n",
      "     |  \n",
      "     |  sparse_resize_and_clear_(...)\n",
      "     |  \n",
      "     |  split_with_sizes(...)\n",
      "     |  \n",
      "     |  sqrt(...)\n",
      "     |      sqrt() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sqrt`\n",
      "     |  \n",
      "     |  sqrt_(...)\n",
      "     |      sqrt_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sqrt`\n",
      "     |  \n",
      "     |  squeeze(...)\n",
      "     |      squeeze(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.squeeze`\n",
      "     |  \n",
      "     |  squeeze_(...)\n",
      "     |      squeeze_(dim=None) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.squeeze`\n",
      "     |  \n",
      "     |  sspaddmm(...)\n",
      "     |  \n",
      "     |  std(...)\n",
      "     |      std(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.std`\n",
      "     |  \n",
      "     |  storage(...)\n",
      "     |      storage() -> torch.Storage\n",
      "     |      \n",
      "     |      Returns the underlying storage.\n",
      "     |  \n",
      "     |  storage_offset(...)\n",
      "     |      storage_offset() -> int\n",
      "     |      \n",
      "     |      Returns :attr:`self` tensor's offset in the underlying storage in terms of\n",
      "     |      number of storage elements (not bytes).\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([1, 2, 3, 4, 5])\n",
      "     |          >>> x.storage_offset()\n",
      "     |          0\n",
      "     |          >>> x[3:].storage_offset()\n",
      "     |          3\n",
      "     |  \n",
      "     |  storage_type(...)\n",
      "     |      storage_type() -> type\n",
      "     |      \n",
      "     |      Returns the type of the underlying storage.\n",
      "     |  \n",
      "     |  stride(...)\n",
      "     |      stride(dim) -> tuple or int\n",
      "     |      \n",
      "     |      Returns the stride of :attr:`self` tensor.\n",
      "     |      \n",
      "     |      Stride is the jump necessary to go from one element to the next one in the\n",
      "     |      specified dimension :attr:`dim`. A tuple of all strides is returned when no\n",
      "     |      argument is passed in. Otherwise, an integer value is returned as the stride in\n",
      "     |      the particular dimension :attr:`dim`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dim (int, optional): the desired dimension in which stride is required\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
      "     |          >>> x.stride()\n",
      "     |          (5, 1)\n",
      "     |          >>>x.stride(0)\n",
      "     |          5\n",
      "     |          >>> x.stride(-1)\n",
      "     |          1\n",
      "     |  \n",
      "     |  sub(...)\n",
      "     |      sub(value, other) -> Tensor\n",
      "     |      \n",
      "     |      Subtracts a scalar or tensor from :attr:`self` tensor. If both :attr:`value` and\n",
      "     |      :attr:`other` are specified, each element of :attr:`other` is scaled by\n",
      "     |      :attr:`value` before being used.\n",
      "     |      \n",
      "     |      When :attr:`other` is a tensor, the shape of :attr:`other` must be\n",
      "     |      :ref:`broadcastable <broadcasting-semantics>` with the shape of the underlying\n",
      "     |      tensor.\n",
      "     |  \n",
      "     |  sub_(...)\n",
      "     |      sub_(x) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.sub`\n",
      "     |  \n",
      "     |  sum(...)\n",
      "     |      sum(dim=None, keepdim=False, dtype=None) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.sum`\n",
      "     |  \n",
      "     |  sum_to_size(...)\n",
      "     |      sum_to_size(*size) -> Tensor\n",
      "     |      \n",
      "     |      Sum ``this`` tensor to :attr:`size`.\n",
      "     |      :attr:`size` must be broadcastable to ``this`` tensor size.\n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  svd(...)\n",
      "     |      svd(some=True, compute_uv=True) -> (Tensor, Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.svd`\n",
      "     |  \n",
      "     |  symeig(...)\n",
      "     |      symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.symeig`\n",
      "     |  \n",
      "     |  t(...)\n",
      "     |      t() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.t`\n",
      "     |  \n",
      "     |  t_(...)\n",
      "     |      t_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.t`\n",
      "     |  \n",
      "     |  take(...)\n",
      "     |      take(indices) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.take`\n",
      "     |  \n",
      "     |  tan(...)\n",
      "     |      tan() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tan`\n",
      "     |  \n",
      "     |  tan_(...)\n",
      "     |      tan_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tan`\n",
      "     |  \n",
      "     |  tanh(...)\n",
      "     |      tanh() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tanh`\n",
      "     |  \n",
      "     |  tanh_(...)\n",
      "     |      tanh_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tanh`\n",
      "     |  \n",
      "     |  to(...)\n",
      "     |      to(*args, **kwargs) -> Tensor\n",
      "     |      \n",
      "     |      Performs Tensor dtype and/or device conversion. A :class:`torch.dtype` and :class:`torch.device` are\n",
      "     |      inferred from the arguments of ``self.to(*args, **kwargs)``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the ``self`` Tensor already\n",
      "     |          has the correct :class:`torch.dtype` and :class:`torch.device`, then ``self`` is returned.\n",
      "     |          Otherwise, the returned tensor is a copy of ``self`` with the desired\n",
      "     |          :class:`torch.dtype` and :class:`torch.device`.\n",
      "     |      \n",
      "     |      Here are the ways to call ``to``:\n",
      "     |      \n",
      "     |      .. function:: to(dtype, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`dtype`\n",
      "     |      \n",
      "     |      .. function:: to(device=None, dtype=None, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with the specified :attr:`device` and (optional)\n",
      "     |          :attr:`dtype`. If :attr:`dtype` is ``None`` it is inferred to be ``self.dtype``.\n",
      "     |          When :attr:`non_blocking`, tries to convert asynchronously with respect to\n",
      "     |          the host if possible, e.g., converting a CPU Tensor with pinned memory to a\n",
      "     |          CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      .. function:: to(other, non_blocking=False, copy=False) -> Tensor\n",
      "     |      \n",
      "     |          Returns a Tensor with same :class:`torch.dtype` and :class:`torch.device` as\n",
      "     |          the Tensor :attr:`other`. When :attr:`non_blocking`, tries to convert\n",
      "     |          asynchronously with respect to the host if possible, e.g., converting a CPU\n",
      "     |          Tensor with pinned memory to a CUDA Tensor.\n",
      "     |          When :attr:`copy` is set, a new Tensor is created even when the Tensor\n",
      "     |          already matches the desired conversion.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu\n",
      "     |          >>> tensor.to(torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64)\n",
      "     |      \n",
      "     |          >>> cuda0 = torch.device('cuda:0')\n",
      "     |          >>> tensor.to(cuda0)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], device='cuda:0')\n",
      "     |      \n",
      "     |          >>> tensor.to(cuda0, dtype=torch.float64)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |      \n",
      "     |          >>> other = torch.randn((), dtype=torch.float64, device=cuda0)\n",
      "     |          >>> tensor.to(other, non_blocking=True)\n",
      "     |          tensor([[-0.5044,  0.0005],\n",
      "     |                  [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')\n",
      "     |  \n",
      "     |  to_dense(...)\n",
      "     |  \n",
      "     |  to_mkldnn(...)\n",
      "     |      to_mkldnn() -> Tensor\n",
      "     |      Returns a copy of the tensor in ``torch.mkldnn`` layout.\n",
      "     |  \n",
      "     |  to_sparse(...)\n",
      "     |      to_sparse(sparseDims) -> Tensor\n",
      "     |      Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in\n",
      "     |      :ref:`coordinate format <sparse-docs>`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          sparseDims (int, optional): the number of sparse dimensions to include in the new sparse tensor\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> d = torch.tensor([[0, 0, 0], [9, 0, 10], [0, 0, 0]])\n",
      "     |          >>> d\n",
      "     |          tensor([[ 0,  0,  0],\n",
      "     |                  [ 9,  0, 10],\n",
      "     |                  [ 0,  0,  0]])\n",
      "     |          >>> d.to_sparse()\n",
      "     |          tensor(indices=tensor([[1, 1],\n",
      "     |                                 [0, 2]]),\n",
      "     |                 values=tensor([ 9, 10]),\n",
      "     |                 size=(3, 3), nnz=2, layout=torch.sparse_coo)\n",
      "     |          >>> d.to_sparse(1)\n",
      "     |          tensor(indices=tensor([[1]]),\n",
      "     |                 values=tensor([[ 9,  0, 10]]),\n",
      "     |                 size=(3, 3), nnz=1, layout=torch.sparse_coo)\n",
      "     |  \n",
      "     |  tolist(...)\n",
      "     |      \"\n",
      "     |      tolist() -> list or number\n",
      "     |      \n",
      "     |      Returns the tensor as a (nested) list. For scalars, a standard\n",
      "     |      Python number is returned, just like with :meth:`~Tensor.item`.\n",
      "     |      Tensors are automatically moved to the CPU first if necessary.\n",
      "     |      \n",
      "     |      This operation is not differentiable.\n",
      "     |      \n",
      "     |      Examples::\n",
      "     |      \n",
      "     |          >>> a = torch.randn(2, 2)\n",
      "     |          >>> a.tolist()\n",
      "     |          [[0.012766935862600803, 0.5415473580360413],\n",
      "     |           [-0.08909505605697632, 0.7729271650314331]]\n",
      "     |          >>> a[0,0].tolist()\n",
      "     |          0.012766935862600803\n",
      "     |  \n",
      "     |  topk(...)\n",
      "     |      topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor)\n",
      "     |      \n",
      "     |      See :func:`torch.topk`\n",
      "     |  \n",
      "     |  trace(...)\n",
      "     |      trace() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trace`\n",
      "     |  \n",
      "     |  transpose(...)\n",
      "     |      transpose(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.transpose`\n",
      "     |  \n",
      "     |  transpose_(...)\n",
      "     |      transpose_(dim0, dim1) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.transpose`\n",
      "     |  \n",
      "     |  triangular_solve(...)\n",
      "     |      triangular_solve(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor)\n",
      "     |      \n",
      "     |      See :func:`torch.triangular_solve`\n",
      "     |  \n",
      "     |  tril(...)\n",
      "     |      tril(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.tril`\n",
      "     |  \n",
      "     |  tril_(...)\n",
      "     |      tril_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.tril`\n",
      "     |  \n",
      "     |  triu(...)\n",
      "     |      triu(k=0) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.triu`\n",
      "     |  \n",
      "     |  triu_(...)\n",
      "     |      triu_(k=0) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.triu`\n",
      "     |  \n",
      "     |  trunc(...)\n",
      "     |      trunc() -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.trunc`\n",
      "     |  \n",
      "     |  trunc_(...)\n",
      "     |      trunc_() -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.trunc`\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(dtype=None, non_blocking=False, **kwargs) -> str or Tensor\n",
      "     |      Returns the type if `dtype` is not provided, else casts this object to\n",
      "     |      the specified type.\n",
      "     |      \n",
      "     |      If this is already of the correct type, no copy is performed and the\n",
      "     |      original object is returned.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dtype (type or string): The desired type\n",
      "     |          non_blocking (bool): If ``True``, and the source is in pinned memory\n",
      "     |              and destination is on the GPU or vice versa, the copy is performed\n",
      "     |              asynchronously with respect to the host. Otherwise, the argument\n",
      "     |              has no effect.\n",
      "     |          **kwargs: For compatibility, may contain the key ``async`` in place of\n",
      "     |              the ``non_blocking`` argument. The ``async`` arg is deprecated.\n",
      "     |  \n",
      "     |  type_as(...)\n",
      "     |      type_as(tensor) -> Tensor\n",
      "     |      \n",
      "     |      Returns this tensor cast to the type of the given tensor.\n",
      "     |      \n",
      "     |      This is a no-op if the tensor is already of the correct type. This is\n",
      "     |      equivalent to ``self.type(tensor.type())``\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          tensor (Tensor): the tensor which has the desired type\n",
      "     |  \n",
      "     |  unbind(...)\n",
      "     |      unbind(dim=0) -> seq\n",
      "     |      \n",
      "     |      See :func:`torch.unbind`\n",
      "     |  \n",
      "     |  unfold(...)\n",
      "     |      unfold(dimension, size, step) -> Tensor\n",
      "     |      \n",
      "     |      Returns a tensor which contains all slices of size :attr:`size` from\n",
      "     |      :attr:`self` tensor in the dimension :attr:`dimension`.\n",
      "     |      \n",
      "     |      Step between two slices is given by :attr:`step`.\n",
      "     |      \n",
      "     |      If `sizedim` is the size of dimension :attr:`dimension` for :attr:`self`, the size of\n",
      "     |      dimension :attr:`dimension` in the returned tensor will be\n",
      "     |      `(sizedim - size) / step + 1`.\n",
      "     |      \n",
      "     |      An additional dimension of size :attr:`size` is appended in the returned tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          dimension (int): dimension in which unfolding happens\n",
      "     |          size (int): the size of each slice that is unfolded\n",
      "     |          step (int): the step between each slice\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.arange(1., 8)\n",
      "     |          >>> x\n",
      "     |          tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])\n",
      "     |          >>> x.unfold(0, 2, 1)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 2.,  3.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 4.,  5.],\n",
      "     |                  [ 5.,  6.],\n",
      "     |                  [ 6.,  7.]])\n",
      "     |          >>> x.unfold(0, 2, 2)\n",
      "     |          tensor([[ 1.,  2.],\n",
      "     |                  [ 3.,  4.],\n",
      "     |                  [ 5.,  6.]])\n",
      "     |  \n",
      "     |  uniform_(...)\n",
      "     |      uniform_(from=0, to=1) -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with numbers sampled from the continuous uniform\n",
      "     |      distribution:\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |          P(x) = \\dfrac{1}{\\text{to} - \\text{from}}\n",
      "     |  \n",
      "     |  unsqueeze(...)\n",
      "     |      unsqueeze(dim) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.unsqueeze`\n",
      "     |  \n",
      "     |  unsqueeze_(...)\n",
      "     |      unsqueeze_(dim) -> Tensor\n",
      "     |      \n",
      "     |      In-place version of :meth:`~Tensor.unsqueeze`\n",
      "     |  \n",
      "     |  values(...)\n",
      "     |      values() -> Tensor\n",
      "     |      \n",
      "     |      If :attr:`self` is a sparse COO tensor (i.e., with ``torch.sparse_coo`` layout),\n",
      "     |      this returns a view of the contained values tensor. Otherwise, this throws an\n",
      "     |      error.\n",
      "     |      \n",
      "     |      See also :meth:`Tensor.indices`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |        This method can only be called on a coalesced sparse tensor. See\n",
      "     |        :meth:`Tensor.coalesce` for details.\n",
      "     |  \n",
      "     |  var(...)\n",
      "     |      var(dim=None, unbiased=True, keepdim=False) -> Tensor\n",
      "     |      \n",
      "     |      See :func:`torch.var`\n",
      "     |  \n",
      "     |  view(...)\n",
      "     |      view(*shape) -> Tensor\n",
      "     |      \n",
      "     |      Returns a new tensor with the same data as the :attr:`self` tensor but of a\n",
      "     |      different :attr:`shape`.\n",
      "     |      \n",
      "     |      The returned tensor shares the same data and must have the same number\n",
      "     |      of elements, but may have a different size. For a tensor to be viewed, the new\n",
      "     |      view size must be compatible with its original size and stride, i.e., each new\n",
      "     |      view dimension must either be a subspace of an original dimension, or only span\n",
      "     |      across original dimensions :math:`d, d+1, \\dots, d+k` that satisfy the following\n",
      "     |      contiguity-like condition that :math:`\\forall i = 0, \\dots, k-1`,\n",
      "     |      \n",
      "     |      .. math::\n",
      "     |      \n",
      "     |        \\text{stride}[i] = \\text{stride}[i+1] \\times \\text{size}[i+1]\n",
      "     |      \n",
      "     |      Otherwise, :meth:`contiguous` needs to be called before the tensor can be\n",
      "     |      viewed. See also: :meth:`reshape`, which returns a view if the shapes are\n",
      "     |      compatible, and copies (equivalent to calling :meth:`contiguous`) otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          shape (torch.Size or int...): the desired size\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> x = torch.randn(4, 4)\n",
      "     |          >>> x.size()\n",
      "     |          torch.Size([4, 4])\n",
      "     |          >>> y = x.view(16)\n",
      "     |          >>> y.size()\n",
      "     |          torch.Size([16])\n",
      "     |          >>> z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
      "     |          >>> z.size()\n",
      "     |          torch.Size([2, 8])\n",
      "     |      \n",
      "     |          >>> a = torch.randn(1, 2, 3, 4)\n",
      "     |          >>> a.size()\n",
      "     |          torch.Size([1, 2, 3, 4])\n",
      "     |          >>> b = a.transpose(1, 2)  # Swaps 2nd and 3rd dimension\n",
      "     |          >>> b.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> c = a.view(1, 3, 2, 4)  # Does not change tensor layout in memory\n",
      "     |          >>> c.size()\n",
      "     |          torch.Size([1, 3, 2, 4])\n",
      "     |          >>> torch.equal(b, c)\n",
      "     |          False\n",
      "     |  \n",
      "     |  view_as(...)\n",
      "     |      view_as(other) -> Tensor\n",
      "     |      \n",
      "     |      View this tensor as the same size as :attr:`other`.\n",
      "     |      ``self.view_as(other)`` is equivalent to ``self.view(other.size())``.\n",
      "     |      \n",
      "     |      Please see :meth:`~Tensor.view` for more information about ``view``.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          other (:class:`torch.Tensor`): The result tensor has the same size\n",
      "     |              as :attr:`other`.\n",
      "     |  \n",
      "     |  where(...)\n",
      "     |      where(condition, y) -> Tensor\n",
      "     |      \n",
      "     |      ``self.where(condition, y)`` is equivalent to ``torch.where(condition, self, y)``.\n",
      "     |      See :func:`torch.where`\n",
      "     |  \n",
      "     |  zero_(...)\n",
      "     |      zero_() -> Tensor\n",
      "     |      \n",
      "     |      Fills :attr:`self` tensor with zeros.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from torch._C._TensorBase:\n",
      "     |  \n",
      "     |  data\n",
      "     |  \n",
      "     |  device\n",
      "     |      Is the :class:`torch.device` where this Tensor is.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  grad\n",
      "     |      This attribute is ``None`` by default and becomes a Tensor the first time a call to\n",
      "     |      :func:`backward` computes gradients for ``self``.\n",
      "     |      The attribute will then contain the gradients computed and future calls to\n",
      "     |      :func:`backward` will accumulate (add) gradients into it.\n",
      "     |  \n",
      "     |  grad_fn\n",
      "     |  \n",
      "     |  is_cuda\n",
      "     |      Is ``True`` if the Tensor is stored on the GPU, ``False`` otherwise.\n",
      "     |  \n",
      "     |  is_leaf\n",
      "     |      All Tensors that have :attr:`requires_grad` which is ``False`` will be leaf Tensors by convention.\n",
      "     |      \n",
      "     |      For Tensors that have :attr:`requires_grad` which is ``True``, they will be leaf Tensors if they were\n",
      "     |      created by the user. This means that they are not the result of an operation and so\n",
      "     |      :attr:`grad_fn` is None.\n",
      "     |      \n",
      "     |      Only leaf Tensors will have their :attr:`grad` populated during a call to :func:`backward`.\n",
      "     |      To get :attr:`grad` populated for non-leaf Tensors, you can use :func:`retain_grad`.\n",
      "     |      \n",
      "     |      Example::\n",
      "     |      \n",
      "     |          >>> a = torch.rand(10, requires_grad=True)\n",
      "     |          >>> a.is_leaf\n",
      "     |          True\n",
      "     |          >>> b = torch.rand(10, requires_grad=True).cuda()\n",
      "     |          >>> b.is_leaf\n",
      "     |          False\n",
      "     |          # b was created by the operation that cast a cpu Tensor into a cuda Tensor\n",
      "     |          >>> c = torch.rand(10, requires_grad=True) + 2\n",
      "     |          >>> c.is_leaf\n",
      "     |          False\n",
      "     |          # c was created by the addition operation\n",
      "     |          >>> d = torch.rand(10).cuda()\n",
      "     |          >>> d.is_leaf\n",
      "     |          True\n",
      "     |          # d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)\n",
      "     |          >>> e = torch.rand(10).cuda().requires_grad_()\n",
      "     |          >>> e.is_leaf\n",
      "     |          True\n",
      "     |          # e requires gradients and has no operations creating it\n",
      "     |          >>> f = torch.rand(10, requires_grad=True, device=\"cuda\")\n",
      "     |          >>> f.is_leaf\n",
      "     |          True\n",
      "     |          # f requires grad, has no operation creating it\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |  \n",
      "     |  is_sparse\n",
      "     |  \n",
      "     |  layout\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  output_nr\n",
      "     |  \n",
      "     |  requires_grad\n",
      "     |      Is ``True`` if gradients need to be computed for this Tensor, ``False`` otherwise.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          The fact that gradients need to be computed for a Tensor do not mean that the :attr:`grad`\n",
      "     |          attribute will be populated, see :attr:`is_leaf` for more details.\n",
      "     |  \n",
      "     |  shape\n",
      "     |  \n",
      "     |  volatile\n",
      "    \n",
      "    class TensorType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      TensorType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get(...) from builtins.PyCapsule\n",
      "     |      get() -> torch._C.TensorType\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TracingState(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      TracingState\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  __str__(...)\n",
      "     |      __str__(self: torch._C.TracingState) -> str\n",
      "     |  \n",
      "     |  graph(...)\n",
      "     |      graph(self: torch._C.TracingState) -> torch._C.Graph\n",
      "     |  \n",
      "     |  pop_scope(...)\n",
      "     |      pop_scope(self: torch._C.TracingState) -> None\n",
      "     |  \n",
      "     |  push_scope(...)\n",
      "     |      push_scope(self: torch._C.TracingState, arg0: str) -> None\n",
      "     |  \n",
      "     |  set_graph(...)\n",
      "     |      set_graph(self: torch._C.TracingState, arg0: torch._C.Graph) -> None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class TupleType(Type)\n",
      "     |  Method resolution order:\n",
      "     |      TupleType\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(...)\n",
      "     |      __init__(self: torch._C.TupleType, arg0: List[torch._C.Type]) -> None\n",
      "     |  \n",
      "     |  elements(...)\n",
      "     |      elements(self: torch._C.TupleType) -> List[torch._C.Type]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Type:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Type(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Type\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(...)\n",
      "     |      __eq__(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  contiguous(...)\n",
      "     |      contiguous(self: torch._C.Type) -> torch._C.Type\n",
      "     |  \n",
      "     |  dim(...)\n",
      "     |      dim(self: torch._C.Type) -> int\n",
      "     |  \n",
      "     |  isSubtypeOf(...)\n",
      "     |      isSubtypeOf(self: torch._C.Type, arg0: torch._C.Type) -> bool\n",
      "     |  \n",
      "     |  kind(...)\n",
      "     |      kind(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  scalarType(...)\n",
      "     |      scalarType(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  sizes(...)\n",
      "     |      sizes(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  str(...)\n",
      "     |      str(self: torch._C.Type) -> str\n",
      "     |  \n",
      "     |  strides(...)\n",
      "     |      strides(self: torch._C.Type) -> List[int]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Use(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Use\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  offset\n",
      "     |  \n",
      "     |  user\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class Value(pybind11_builtins.pybind11_object)\n",
      "     |  Method resolution order:\n",
      "     |      Value\n",
      "     |      pybind11_builtins.pybind11_object\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(...)\n",
      "     |      __repr__(self: torch._C.Value) -> str\n",
      "     |  \n",
      "     |  copyMetadata(...)\n",
      "     |      copyMetadata(self: torch._C.Value, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  inferTypeFrom(...)\n",
      "     |      inferTypeFrom(self: torch._C.Value, arg0: at::Tensor) -> None\n",
      "     |  \n",
      "     |  isCompleteTensor(...)\n",
      "     |      isCompleteTensor(self: torch._C.Value) -> bool\n",
      "     |  \n",
      "     |  node(...)\n",
      "     |      node(self: torch._C.Value) -> torch::jit::Node\n",
      "     |  \n",
      "     |  offset(...)\n",
      "     |      offset(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  replaceAllUsesWith(...)\n",
      "     |      replaceAllUsesWith(self: torch._C.Value, arg0: torch._C.Value) -> None\n",
      "     |  \n",
      "     |  requires_grad(...)\n",
      "     |      requires_grad(self: torch._C.Value) -> bool\n",
      "     |  \n",
      "     |  setType(...)\n",
      "     |      setType(self: torch._C.Value, arg0: c10::Type) -> torch._C.Value\n",
      "     |  \n",
      "     |  setTypeAs(...)\n",
      "     |      setTypeAs(self: torch._C.Value, arg0: torch._C.Value) -> torch._C.Value\n",
      "     |  \n",
      "     |  setUniqueName(...)\n",
      "     |      setUniqueName(self: torch._C.Value, arg0: str) -> torch._C.Value\n",
      "     |  \n",
      "     |  toIValue(...)\n",
      "     |      toIValue(self: torch._C.Value) -> Optional[IValue]\n",
      "     |  \n",
      "     |  type(...)\n",
      "     |      type(*args, **kwargs)\n",
      "     |      Overloaded function.\n",
      "     |      \n",
      "     |      1. type(self: torch._C.Value) -> c10::Type\n",
      "     |      \n",
      "     |      2. type(self: torch._C.Value) -> c10::Type\n",
      "     |  \n",
      "     |  unique(...)\n",
      "     |      unique(self: torch._C.Value) -> int\n",
      "     |  \n",
      "     |  uniqueName(...)\n",
      "     |      uniqueName(self: torch._C.Value) -> str\n",
      "     |  \n",
      "     |  uses(...)\n",
      "     |      uses(self: torch._C.Value) -> List[torch::jit::Use]\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class device(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  index\n",
      "     |  \n",
      "     |  type\n",
      "    \n",
      "    class dtype(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  is_floating_point\n",
      "    \n",
      "    class enable_grad(builtins.object)\n",
      "     |  Context-manager that enables gradient calculation.\n",
      "     |  \n",
      "     |  Enables gradient calculation inside a :class:`~no_grad` context. This has\n",
      "     |  no effect outside of :class:`~no_grad`.\n",
      "     |  \n",
      "     |  Also functions as a decorator.\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...   with torch.enable_grad():\n",
      "     |      ...     y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      True\n",
      "     |      >>> y.backward()\n",
      "     |      >>> x.grad\n",
      "     |      >>> @torch.enable_grad()\n",
      "     |      ... def doubler(x):\n",
      "     |      ...     return x * 2\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...     z = doubler(x)\n",
      "     |      >>> z.requires_grad\n",
      "     |      True\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, func)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class finfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bits\n",
      "     |  \n",
      "     |  eps\n",
      "     |  \n",
      "     |  max\n",
      "     |  \n",
      "     |  min\n",
      "     |  \n",
      "     |  tiny\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class iinfo(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bits\n",
      "     |  \n",
      "     |  max\n",
      "     |  \n",
      "     |  min\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class layout(builtins.object)\n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "    \n",
      "    class no_grad(builtins.object)\n",
      "     |  Context-manager that disabled gradient calculation.\n",
      "     |  \n",
      "     |  Disabling gradient calculation is useful for inference, when you are sure\n",
      "     |  that you will not call :meth:`Tensor.backward()`. It will reduce memory\n",
      "     |  consumption for computations that would otherwise have `requires_grad=True`.\n",
      "     |  In this mode, the result of every computation will have\n",
      "     |  `requires_grad=False`, even when the inputs have `requires_grad=True`.\n",
      "     |  \n",
      "     |  Also functions as a decorator.\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> with torch.no_grad():\n",
      "     |      ...   y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |      >>> @torch.no_grad()\n",
      "     |      ... def doubler(x):\n",
      "     |      ...     return x * 2\n",
      "     |      >>> z = doubler(x)\n",
      "     |      >>> z.requires_grad\n",
      "     |      False\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, func)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class set_grad_enabled(builtins.object)\n",
      "     |  Context-manager that sets gradient calculation to on or off.\n",
      "     |  \n",
      "     |  ``set_grad_enabled`` will enable or disable grads based on its argument :attr:`mode`.\n",
      "     |  It can be used as a context-manager or as a function.\n",
      "     |  \n",
      "     |  Arguments:\n",
      "     |      mode (bool): Flag whether to enable grad (``True``), or disable\n",
      "     |                   (``False``). This can be used to conditionally enable\n",
      "     |                   gradients.\n",
      "     |  \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> x = torch.tensor([1], requires_grad=True)\n",
      "     |      >>> is_train = False\n",
      "     |      >>> with torch.set_grad_enabled(is_train):\n",
      "     |      ...   y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |      >>> torch.set_grad_enabled(True)\n",
      "     |      >>> y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      True\n",
      "     |      >>> torch.set_grad_enabled(False)\n",
      "     |      >>> y = x * 2\n",
      "     |      >>> y.requires_grad\n",
      "     |      False\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, *args)\n",
      "     |  \n",
      "     |  __init__(self, mode)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    chunk(...)\n",
      "        chunk(tensor, chunks, dim=0) -> List of Tensors\n",
      "        \n",
      "        Splits a tensor into a specific number of chunks.\n",
      "        \n",
      "        Last chunk will be smaller if the tensor size along the given dimension\n",
      "        :attr:`dim` is not divisible by :attr:`chunks`.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor (Tensor): the tensor to split\n",
      "            chunks (int): number of chunks to return\n",
      "            dim (int): dimension along which to split the tensor\n",
      "    \n",
      "    fork(...) method of builtins.PyCapsule instance\n",
      "        fork(*args) -> torch._C.Future\n",
      "    \n",
      "    get_default_dtype(...)\n",
      "        get_default_dtype() -> torch.dtype\n",
      "        \n",
      "        Get the current default floating point :class:`torch.dtype`.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.get_default_dtype()  # initial default for floating point is torch.float32\n",
      "            torch.float32\n",
      "            >>> torch.set_default_dtype(torch.float64)\n",
      "            >>> torch.get_default_dtype()  # default is now changed to torch.float64\n",
      "            torch.float64\n",
      "            >>> torch.set_default_tensor_type(torch.FloatTensor)  # setting tensor type also affects this\n",
      "            >>> torch.get_default_dtype()  # changed to torch.float32, the dtype for torch.FloatTensor\n",
      "            torch.float32\n",
      "    \n",
      "    get_num_threads(...)\n",
      "        get_num_threads() -> int\n",
      "        \n",
      "        Gets the number of threads used for parallelizing CPU operations\n",
      "    \n",
      "    get_rng_state()\n",
      "        Returns the random number generator state as a `torch.ByteTensor`.\n",
      "    \n",
      "    import_ir_module(...) method of builtins.PyCapsule instance\n",
      "        import_ir_module(arg0: Callable[[List[str]], torch._C.ScriptModule], arg1: str, arg2: object, arg3: torch._C.ExtraFilesMap) -> None\n",
      "    \n",
      "    import_ir_module_from_buffer(...) method of builtins.PyCapsule instance\n",
      "        import_ir_module_from_buffer(arg0: Callable[[List[str]], torch._C.ScriptModule], arg1: str, arg2: object, arg3: torch._C.ExtraFilesMap) -> None\n",
      "    \n",
      "    initial_seed()\n",
      "        Returns the initial seed for generating random numbers as a\n",
      "        Python `long`.\n",
      "    \n",
      "    is_anomaly_enabled(...)\n",
      "    \n",
      "    is_grad_enabled(...)\n",
      "    \n",
      "    is_storage(obj)\n",
      "        Returns True if `obj` is a PyTorch storage object.\n",
      "        \n",
      "        Args:\n",
      "            obj (Object): Object to test\n",
      "    \n",
      "    is_tensor(obj)\n",
      "        Returns True if `obj` is a PyTorch tensor.\n",
      "        \n",
      "        Args:\n",
      "            obj (Object): Object to test\n",
      "    \n",
      "    load(f, map_location=None, pickle_module=<module 'pickle' from '/opt/conda/lib/python3.6/pickle.py'>, **pickle_load_args)\n",
      "        Loads an object saved with :func:`torch.save` from a file.\n",
      "        \n",
      "        :meth:`torch.load` uses Python's unpickling facilities but treats storages,\n",
      "        which underlie tensors, specially. They are first deserialized on the\n",
      "        CPU and are then moved to the device they were saved from. If this fails\n",
      "        (e.g. because the run time system doesn't have certain devices), an exception\n",
      "        is raised. However, storages can be dynamically remapped to an alternative\n",
      "        set of devices using the `map_location` argument.\n",
      "        \n",
      "        If `map_location` is a callable, it will be called once for each serialized\n",
      "        storage with two arguments: storage and location. The storage argument\n",
      "        will be the initial deserialization of the storage, residing on the CPU.\n",
      "        Each serialized storage has a location tag associated with it which\n",
      "        identifies the device it was saved from, and this tag is the second\n",
      "        argument passed to map_location. The builtin location tags are `'cpu'` for\n",
      "        CPU tensors and `'cuda:device_id'` (e.g. `'cuda:2'`) for CUDA tensors.\n",
      "        `map_location` should return either None or a storage. If `map_location` returns\n",
      "        a storage, it will be used as the final deserialized object, already moved to\n",
      "        the right device. Otherwise, :math:`torch.load` will fall back to the default\n",
      "        behavior, as if `map_location` wasn't specified.\n",
      "        \n",
      "        If `map_location` is a string, it should be a device tag, where all tensors\n",
      "        should be loaded.\n",
      "        \n",
      "        Otherwise, if `map_location` is a dict, it will be used to remap location tags\n",
      "        appearing in the file (keys), to ones that specify where to put the\n",
      "        storages (values).\n",
      "        \n",
      "        User extensions can register their own location tags and tagging and\n",
      "        deserialization methods using `register_package`.\n",
      "        \n",
      "        Args:\n",
      "            f: a file-like object (has to implement read, readline, tell, and seek),\n",
      "                or a string containing a file name\n",
      "            map_location: a function, torch.device, string or a dict specifying how to remap storage\n",
      "                locations\n",
      "            pickle_module: module used for unpickling metadata and objects (has to\n",
      "                match the pickle_module used to serialize file)\n",
      "            pickle_load_args: optional keyword arguments passed over to\n",
      "                ``pickle_module.load`` and ``pickle_module.Unpickler``, e.g.,\n",
      "                ``encoding=...``.\n",
      "        \n",
      "        .. note::\n",
      "            When you call :meth:`torch.load()` on a file which contains GPU tensors, those tensors\n",
      "            will be loaded to GPU by default. You can call `torch.load(.., map_location='cpu')`\n",
      "            and then :meth:`load_state_dict` to avoid GPU RAM surge when loading a model checkpoint.\n",
      "        \n",
      "        .. note::\n",
      "            In Python 3, when loading files saved by Python 2, you may encounter\n",
      "            ``UnicodeDecodeError: 'ascii' codec can't decode byte 0x...``. This is\n",
      "            caused by the difference of handling in byte strings in Python2 and\n",
      "            Python 3. You may use extra ``encoding`` keyword argument to specify how\n",
      "            these objects should be loaded, e.g., ``encoding='latin1'`` decodes them\n",
      "            to strings using ``latin1`` encoding, and ``encoding='bytes'`` keeps them\n",
      "            as byte arrays which can be decoded later with ``byte_array.decode(...)``.\n",
      "        \n",
      "        Example:\n",
      "            >>> torch.load('tensors.pt')\n",
      "            # Load all tensors onto the CPU\n",
      "            >>> torch.load('tensors.pt', map_location=torch.device('cpu'))\n",
      "            # Load all tensors onto the CPU, using a function\n",
      "            >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage)\n",
      "            # Load all tensors onto GPU 1\n",
      "            >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))\n",
      "            # Map tensors from GPU 1 to GPU 0\n",
      "            >>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})\n",
      "            # Load tensor from io.BytesIO object\n",
      "            >>> with open('tensor.pt', 'rb') as f:\n",
      "                    buffer = io.BytesIO(f.read())\n",
      "            >>> torch.load(buffer)\n",
      "    \n",
      "    manual_seed(seed)\n",
      "        Sets the seed for generating random numbers. Returns a\n",
      "        `torch._C.Generator` object.\n",
      "        \n",
      "        Args:\n",
      "            seed (int): The desired seed.\n",
      "    \n",
      "    matmul(...)\n",
      "        matmul(tensor1, tensor2, out=None) -> Tensor\n",
      "        \n",
      "        Matrix product of two tensors.\n",
      "        \n",
      "        The behavior depends on the dimensionality of the tensors as follows:\n",
      "        \n",
      "        - If both tensors are 1-dimensional, the dot product (scalar) is returned.\n",
      "        - If both arguments are 2-dimensional, the matrix-matrix product is returned.\n",
      "        - If the first argument is 1-dimensional and the second argument is 2-dimensional,\n",
      "          a 1 is prepended to its dimension for the purpose of the matrix multiply.\n",
      "          After the matrix multiply, the prepended dimension is removed.\n",
      "        - If the first argument is 2-dimensional and the second argument is 1-dimensional,\n",
      "          the matrix-vector product is returned.\n",
      "        - If both arguments are at least 1-dimensional and at least one argument is\n",
      "          N-dimensional (where N > 2), then a batched matrix multiply is returned.  If the first\n",
      "          argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the\n",
      "          batched matrix multiply and removed after.  If the second argument is 1-dimensional, a\n",
      "          1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.\n",
      "          The non-matrix (i.e. batch) dimensions are :ref:`broadcasted <broadcasting-semantics>` (and thus\n",
      "          must be broadcastable).  For example, if :attr:`tensor1` is a\n",
      "          :math:`(j \\times 1 \\times n \\times m)` tensor and :attr:`tensor2` is a :math:`(k \\times m \\times p)`\n",
      "          tensor, :attr:`out` will be an :math:`(j \\times k \\times n \\times p)` tensor.\n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            The 1-dimensional dot product version of this function does not support an :attr:`out` parameter.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor1 (Tensor): the first tensor to be multiplied\n",
      "            tensor2 (Tensor): the second tensor to be multiplied\n",
      "            out (Tensor, optional): the output tensor\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> # vector x vector\n",
      "            >>> tensor1 = torch.randn(3)\n",
      "            >>> tensor2 = torch.randn(3)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([])\n",
      "            >>> # matrix x vector\n",
      "            >>> tensor1 = torch.randn(3, 4)\n",
      "            >>> tensor2 = torch.randn(4)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([3])\n",
      "            >>> # batched matrix x broadcasted vector\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(4)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3])\n",
      "            >>> # batched matrix x batched matrix\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(10, 4, 5)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "            >>> # batched matrix x broadcasted matrix\n",
      "            >>> tensor1 = torch.randn(10, 3, 4)\n",
      "            >>> tensor2 = torch.randn(4, 5)\n",
      "            >>> torch.matmul(tensor1, tensor2).size()\n",
      "            torch.Size([10, 3, 5])\n",
      "    \n",
      "    merge_type_from_type_comment(...) method of builtins.PyCapsule instance\n",
      "        merge_type_from_type_comment(arg0: torch._C._jit_tree_views.Decl, arg1: torch._C._jit_tree_views.Decl, arg2: bool) -> torch._C._jit_tree_views.Decl\n",
      "    \n",
      "    parse_ir(...) method of builtins.PyCapsule instance\n",
      "        parse_ir(arg0: str) -> torch::jit::Graph\n",
      "    \n",
      "    parse_type_comment(...) method of builtins.PyCapsule instance\n",
      "        parse_type_comment(arg0: str) -> torch._C._jit_tree_views.Decl\n",
      "    \n",
      "    rand(...)\n",
      "        rand(*sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with random numbers from a uniform distribution\n",
      "        on the interval :math:`[0, 1)`\n",
      "        \n",
      "        The shape of the tensor is defined by the variable argument :attr:`sizes`.\n",
      "        \n",
      "        Args:\n",
      "            sizes (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "            out (Tensor, optional): the output tensor\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.rand(4)\n",
      "            tensor([ 0.5204,  0.2503,  0.3525,  0.5673])\n",
      "            >>> torch.rand(2, 3)\n",
      "            tensor([[ 0.8237,  0.5781,  0.6879],\n",
      "                    [ 0.3816,  0.7249,  0.0998]])\n",
      "    \n",
      "    randn(...)\n",
      "        randn(*sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "        \n",
      "        Returns a tensor filled with random numbers from a normal distribution\n",
      "        with mean `0` and variance `1` (also called the standard normal\n",
      "        distribution).\n",
      "        \n",
      "        .. math::\n",
      "            \\text{out}_{i} \\sim \\mathcal{N}(0, 1)\n",
      "        \n",
      "        The shape of the tensor is defined by the variable argument :attr:`sizes`.\n",
      "        \n",
      "        Args:\n",
      "            sizes (int...): a sequence of integers defining the shape of the output tensor.\n",
      "                Can be a variable number of arguments or a collection like a list or tuple.\n",
      "            out (Tensor, optional): the output tensor\n",
      "            dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "                Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "            layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "                Default: ``torch.strided``.\n",
      "            device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "                Default: if ``None``, uses the current device for the default tensor type\n",
      "                (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "                for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "            requires_grad (bool, optional): If autograd should record operations on the\n",
      "                returned tensor. Default: ``False``.\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.randn(4)\n",
      "            tensor([-2.1436,  0.9966,  2.3426, -0.6366])\n",
      "            >>> torch.randn(2, 3)\n",
      "            tensor([[ 1.5954,  2.8929, -1.0923],\n",
      "                    [ 1.1719, -0.4709, -0.1996]])\n",
      "    \n",
      "    save(obj, f, pickle_module=<module 'pickle' from '/opt/conda/lib/python3.6/pickle.py'>, pickle_protocol=2)\n",
      "        Saves an object to a disk file.\n",
      "        \n",
      "        See also: :ref:`recommend-saving-models`\n",
      "        \n",
      "        Args:\n",
      "            obj: saved object\n",
      "            f: a file-like object (has to implement write and flush) or a string\n",
      "               containing a file name\n",
      "            pickle_module: module used for pickling metadata and objects\n",
      "            pickle_protocol: can be specified to override the default protocol\n",
      "        \n",
      "        .. warning::\n",
      "            If you are using Python 2, torch.save does NOT support StringIO.StringIO\n",
      "            as a valid file-like object. This is because the write method should return\n",
      "            the number of bytes written; StringIO.write() does not do this.\n",
      "        \n",
      "            Please use something like io.BytesIO instead.\n",
      "        \n",
      "        Example:\n",
      "            >>> # Save to file\n",
      "            >>> x = torch.tensor([0, 1, 2, 3, 4])\n",
      "            >>> torch.save(x, 'tensor.pt')\n",
      "            >>> # Save to io.BytesIO buffer\n",
      "            >>> buffer = io.BytesIO()\n",
      "            >>> torch.save(x, buffer)\n",
      "    \n",
      "    set_anomaly_enabled(...)\n",
      "    \n",
      "    set_default_tensor_type(t)\n",
      "        Sets the default ``torch.Tensor`` type to floating point tensor type\n",
      "        :attr:`t`. This type will also be used as default floating point type for\n",
      "        type inference in :func:`torch.tensor`.\n",
      "        \n",
      "        The default floating point tensor type is initially ``torch.FloatTensor``.\n",
      "        \n",
      "        Args:\n",
      "            t (type or string): the floating point tensor type or its name\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.tensor([1.2, 3]).dtype    # initial default for floating point is torch.float32\n",
      "            torch.float32\n",
      "            >>> torch.set_default_tensor_type(torch.DoubleTensor)\n",
      "            >>> torch.tensor([1.2, 3]).dtype    # a new floating point tensor\n",
      "            torch.float64\n",
      "    \n",
      "    set_flush_denormal(...)\n",
      "        set_flush_denormal(mode) -> bool\n",
      "        \n",
      "        Disables denormal floating numbers on CPU.\n",
      "        \n",
      "        Returns ``True`` if your system supports flushing denormal numbers and it\n",
      "        successfully configures flush denormal mode.  :meth:`~torch.set_flush_denormal`\n",
      "        is only supported on x86 architectures supporting SSE3.\n",
      "        \n",
      "        Args:\n",
      "            mode (bool): Controls whether to enable flush denormal mode or not\n",
      "        \n",
      "        Example::\n",
      "        \n",
      "            >>> torch.set_flush_denormal(True)\n",
      "            True\n",
      "            >>> torch.tensor([1e-323], dtype=torch.float64)\n",
      "            tensor([ 0.], dtype=torch.float64)\n",
      "            >>> torch.set_flush_denormal(False)\n",
      "            True\n",
      "            >>> torch.tensor([1e-323], dtype=torch.float64)\n",
      "            tensor(9.88131e-324 *\n",
      "                   [ 1.0000], dtype=torch.float64)\n",
      "    \n",
      "    set_num_threads(...)\n",
      "        set_num_threads(int)\n",
      "        \n",
      "        Sets the number of threads used for parallelizing CPU operations.\n",
      "        WARNING:\n",
      "        To ensure that the correct number of threads is used, set_num_threads\n",
      "        must be called before running eager, JIT or autograd code.\n",
      "    \n",
      "    set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None)\n",
      "        Set options for printing. Items shamelessly taken from NumPy\n",
      "        \n",
      "        Args:\n",
      "            precision: Number of digits of precision for floating point output\n",
      "                (default = 4).\n",
      "            threshold: Total number of array elements which trigger summarization\n",
      "                rather than full `repr` (default = 1000).\n",
      "            edgeitems: Number of array items in summary at beginning and end of\n",
      "                each dimension (default = 3).\n",
      "            linewidth: The number of characters per line for the purpose of\n",
      "                inserting line breaks (default = 80). Thresholded matrices will\n",
      "                ignore this parameter.\n",
      "            profile: Sane defaults for pretty printing. Can override with any of\n",
      "                the above options. (any one of `default`, `short`, `full`)\n",
      "            sci_mode: Enable (True) or disable (False) scientific notation. If\n",
      "                None (default) is specified, the value is defined by `_Formatter`\n",
      "    \n",
      "    set_rng_state(new_state)\n",
      "        Sets the random number generator state.\n",
      "        \n",
      "        Args:\n",
      "            new_state (torch.ByteTensor): The desired state\n",
      "    \n",
      "    split(tensor, split_size_or_sections, dim=0)\n",
      "        Splits the tensor into chunks.\n",
      "        \n",
      "        If :attr:`split_size_or_sections` is an integer type, then :attr:`tensor` will\n",
      "        be split into equally sized chunks (if possible). Last chunk will be smaller if\n",
      "        the tensor size along the given dimension :attr:`dim` is not divisible by\n",
      "        :attr:`split_size`.\n",
      "        \n",
      "        If :attr:`split_size_or_sections` is a list, then :attr:`tensor` will be split\n",
      "        into ``len(split_size_or_sections)`` chunks with sizes in :attr:`dim` according\n",
      "        to :attr:`split_size_or_sections`.\n",
      "        \n",
      "        Arguments:\n",
      "            tensor (Tensor): tensor to split.\n",
      "            split_size_or_sections (int) or (list(int)): size of a single chunk or\n",
      "                list of sizes for each chunk\n",
      "            dim (int): dimension along which to split the tensor.\n",
      "    \n",
      "    stack(...)\n",
      "        stack(seq, dim=0, out=None) -> Tensor\n",
      "        \n",
      "        Concatenates sequence of tensors along a new dimension.\n",
      "        \n",
      "        All tensors need to be of the same size.\n",
      "        \n",
      "        Arguments:\n",
      "            seq (sequence of Tensors): sequence of tensors to concatenate\n",
      "            dim (int): dimension to insert. Has to be between 0 and the number\n",
      "                of dimensions of concatenated tensors (inclusive)\n",
      "            out (Tensor, optional): the output tensor\n",
      "    \n",
      "    typename(o)\n",
      "    \n",
      "    wait(...) method of builtins.PyCapsule instance\n",
      "        wait(arg0: torch._C.Future) -> IValue\n",
      "\n",
      "DATA\n",
      "    AVG = AggregationType.AVG\n",
      "    SUM = AggregationType.SUM\n",
      "    __all__ = ['typename', 'is_tensor', 'is_storage', 'set_default_tensor_...\n",
      "    default_generator = <torch._C.Generator object>\n",
      "    has_cuda = True\n",
      "    has_cudnn = True\n",
      "    has_lapack = True\n",
      "    has_mkl = True\n",
      "    has_mkldnn = True\n",
      "    has_openmp = True\n",
      "\n",
      "VERSION\n",
      "    1.1.0\n",
      "\n",
      "FILE\n",
      "    /opt/conda/lib/python3.6/site-packages/torch/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
